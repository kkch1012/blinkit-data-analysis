# Blinkit ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ìƒì„¸ ë¶„ì„ ë¬¸ì„œ

## ğŸ“‹ ëª©ì°¨
1. [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
2. [1ë‹¨ê³„: ì´ˆê¸° ë°ì´í„° íƒìƒ‰](#1ë‹¨ê³„-ì´ˆê¸°-ë°ì´í„°-íƒìƒ‰)
3. [2ë‹¨ê³„: ì›ë³¸ ë°ì´í„° ì†ŒìŠ¤ë³„ ë³‘í•©](#2ë‹¨ê³„-ì›ë³¸-ë°ì´í„°-ì†ŒìŠ¤ë³„-ë³‘í•©)
4. [3ë‹¨ê³„: ì¬ê³  ë°ì´í„° ë³„ë„ ì²˜ë¦¬](#3ë‹¨ê³„-ì¬ê³ -ë°ì´í„°-ë³„ë„-ì²˜ë¦¬)
5. [4ë‹¨ê³„: ì£¼ë¬¸ ë°ì´í„° ì¬êµ¬ì„±](#4ë‹¨ê³„-ì£¼ë¬¸-ë°ì´í„°-ì¬êµ¬ì„±)
6. [5ë‹¨ê³„: ìµœì¢… ë°ì´í„°ì…‹ ìƒì„±](#5ë‹¨ê³„-ìµœì¢…-ë°ì´í„°ì…‹-ìƒì„±)
7. [6ë‹¨ê³„: ìƒê´€ê´€ê³„ ë¶„ì„](#6ë‹¨ê³„-ìƒê´€ê´€ê³„-ë¶„ì„)
8. [7ë‹¨ê³„: ì‹œê³„ì—´ í”¼ì²˜ ìƒì„±](#7ë‹¨ê³„-ì‹œê³„ì—´-í”¼ì²˜-ìƒì„±)
9. [8ë‹¨ê³„: ê¸°ë³¸ ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸](#8ë‹¨ê³„-ê¸°ë³¸-ìˆ˜ìš”-ì˜ˆì¸¡-ëª¨ë¸)
10. [9ë‹¨ê³„: ë§ˆì¼€íŒ… ë°ì´í„° ê²°í•©](#9ë‹¨ê³„-ë§ˆì¼€íŒ…-ë°ì´í„°-ê²°í•©)
11. [10ë‹¨ê³„: ë§ˆì¼€íŒ… í¬í•¨ ìˆ˜ìš” ì˜ˆì¸¡](#10ë‹¨ê³„-ë§ˆì¼€íŒ…-í¬í•¨-ìˆ˜ìš”-ì˜ˆì¸¡)
12. [11ë‹¨ê³„: ì¬ê³  ë°ì´í„° í†µí•©](#11ë‹¨ê³„-ì¬ê³ -ë°ì´í„°-í†µí•©)
13. [12ë‹¨ê³„: ìƒê´€ê´€ê³„ ë¶„ì„](#12ë‹¨ê³„-ìƒê´€ê´€ê³„-ë¶„ì„)
14. [13ë‹¨ê³„: ì£¼ë³„ ë°ì´í„° ì§‘ê³„](#13ë‹¨ê³„-ì£¼ë³„-ë°ì´í„°-ì§‘ê³„)
15. [14ë‹¨ê³„: ì£¼ë³„+ì œí’ˆë³„ ë¶„ì„](#14ë‹¨ê³„-ì£¼ë³„ì œí’ˆë³„-ë¶„ì„)
16. [15ë‹¨ê³„: Top 10 ìƒí’ˆ ë¶„ì„](#15ë‹¨ê³„-top-10-ìƒí’ˆ-ë¶„ì„)
17. [16ë‹¨ê³„: ê³ ë„í™” ëª¨ë¸](#16ë‹¨ê³„-ê³ ë„í™”-ëª¨ë¸)
18. [17ë‹¨ê³„: ARIMA ì‹œê³„ì—´ ëª¨ë¸](#17ë‹¨ê³„-arima-ì‹œê³„ì—´-ëª¨ë¸)
19. [18ë‹¨ê³„: ì•™ìƒë¸” ëª¨ë¸](#18ë‹¨ê³„-ì•™ìƒë¸”-ëª¨ë¸)
20. [19ë‹¨ê³„: ìµœì¢… ì¬ê³  ê³„íš ë¦¬í¬íŠ¸](#19ë‹¨ê³„-ìµœì¢…-ì¬ê³ -ê³„íš-ë¦¬í¬íŠ¸)
21. [ì „ì²´ í”„ë¡œì„¸ìŠ¤ ìš”ì•½](#ì „ì²´-í”„ë¡œì„¸ìŠ¤-ìš”ì•½)

---

## í”„ë¡œì íŠ¸ ê°œìš”

### ëª©ì 
Blinkit ì˜¨ë¼ì¸ ì‡¼í•‘ëª°ì˜ ì£¼ë¬¸, ìƒí’ˆ, ë°°ì†¡, ê³ ê°, í”¼ë“œë°±, ì¬ê³ , ë§ˆì¼€íŒ… ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ **ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸**ì„ êµ¬ì¶•í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì£¼ê°„ ì¬ê³  ê³„íš ë° ê¶Œì¥ ì£¼ë¬¸ëŸ‰**ì„ ì‚°ì¶œí•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.

### ë°ì´í„° ì†ŒìŠ¤
ì´ **7ê°œì˜ ì›ë³¸ CSV íŒŒì¼**ì„ ì‚¬ìš©:
1. `blinkit_orders.csv` - ì£¼ë¬¸ ê¸°ë³¸ ì •ë³´
2. `blinkit_order_items.csv` - ì£¼ë¬¸ ìƒì„¸ (ìƒí’ˆë³„ ìˆ˜ëŸ‰, ë‹¨ê°€)
3. `blinkit_products.csv` - ìƒí’ˆ ë§ˆìŠ¤í„° ì •ë³´
4. `blinkit_customers.csv` - ê³ ê° ì •ë³´
5. `blinkit_delivery_performance.csv` - ë°°ì†¡ ì„±ê³¼ ë°ì´í„°
6. `blinkit_customer_feedback.csv` - ê³ ê° í”¼ë“œë°± ë° í‰ì 
7. `blinkit_inventory.csv` - ì¬ê³  ì…ê³ /íŒŒì† ê¸°ë¡
8. `blinkit_marketing_performance.csv` - ë§ˆì¼€íŒ… ì„±ê³¼ ë°ì´í„°

### ìµœì¢… ì‚°ì¶œë¬¼
- `blinkit_final_data.csv` - í†µí•© ìµœì¢… ë°ì´í„° (5,000í–‰, 14ì»¬ëŸ¼)
- `blinkit_daily_data.csv` - ì¼ë³„ ì§‘ê³„ ë°ì´í„° (4,181í–‰, 14ì»¬ëŸ¼)
- `blinkit_weekly_data.csv` - ì£¼ë³„ ì§‘ê³„ ë°ì´í„° (87í–‰, 8ì»¬ëŸ¼)
- `blinkit_weekly_product_analysis.csv` - ì£¼ë³„+ì œí’ˆë³„ ë°ì´í„°
- `weekly_inventory_plan.csv` - ì£¼ê°„ ì¬ê³  ê³„íš ë¦¬í¬íŠ¸
- `blinkit_final_ensemble_report.csv` - ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸

---

## 1ë‹¨ê³„: ì´ˆê¸° ë°ì´í„° íƒìƒ‰

### Cell 0: ê¸°ë³¸ ë°ì´í„° ë¡œë“œ
```python
df = pd.read_csv("data\ë¸”ë§í‚·_ë§ˆìŠ¤í„°_ë°ì´í„°_ìµœì¢….csv")
df1 = pd.read_csv("data\ë¸”ë§í‚·_ë§ˆìŠ¤í„°_ë°ì´í„°_í•œê¸€ì»¬ëŸ¼.csv")
```

**ëª©ì **: ê¸°ì¡´ì— ì „ì²˜ë¦¬ëœ ë§ˆìŠ¤í„° ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ë°ì´í„° êµ¬ì¡°ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.

**ì²˜ë¦¬ ë‚´ìš©**:
- ë‘ ê°œì˜ ë§ˆìŠ¤í„° ë°ì´í„° íŒŒì¼ì„ ë¡œë“œ
- ê° íŒŒì¼ì˜ í˜•íƒœì™€ ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸

### Cell 1-11: ë°ì´í„° íƒìƒ‰ ë° í™•ì¸

**Cell 1-2**: ë°ì´í„° í˜•íƒœ í™•ì¸
- `df.shape`, `df1.shape`ë¡œ í–‰ê³¼ ì—´ì˜ ê°œìˆ˜ í™•ì¸

**Cell 3-5**: ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸
- `df.columns`, `df1.columns`ë¡œ ì»¬ëŸ¼ëª… í™•ì¸
- í•œê¸€ ì»¬ëŸ¼ëª…ê³¼ ì˜ë¬¸ ì»¬ëŸ¼ëª… ë¹„êµ

**Cell 6-9**: ê°’ ë¶„í¬ í™•ì¸
- `ìƒí’ˆ_ID`, `ìƒí’ˆëª…`, `ì¹´í…Œê³ ë¦¬`ì˜ ê°’ ë¶„í¬ í™•ì¸
- `value_counts()`ë¡œ ê° ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ê³¼ ë¹ˆë„ íŒŒì•…

**Cell 10**: í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
```python
df_first = df1[['ì£¼ë¬¸ì¼ì', 'ì•½ì†_ë°°ì†¡ì‹œê°„', 'ì‹¤ì œ_ë°°ì†¡ì‹œê°„', 'ë°°ì†¡ìƒíƒœ_ì£¼ë¬¸', 
                'ì£¼ë¬¸_ì´ì•¡', 'ìˆ˜ëŸ‰', 'ë‹¨ê°€', 'ìƒí’ˆëª…', 'ì¹´í…Œê³ ë¦¬', 'ë¸Œëœë“œ', 
                'ê°€ê²©', 'ë§ˆì§„ìœ¨_í¼ì„¼íŠ¸', 'ìœ í†µê¸°í•œ_ì¼ìˆ˜', 'ë°°ì†¡_ì†Œìš”ì‹œê°„_ë¶„', 
                'ê±°ë¦¬_km', 'ë°°ì†¡ìƒíƒœ_ë°°ì†¡', 'ì§€ì—°_ì‚¬ìœ ', 'ê°ì„±', 'ì§€ì—­', 
                'ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸', 'ì´_ì£¼ë¬¸ìˆ˜', 'í‰ê· _ì£¼ë¬¸ê¸ˆì•¡']]
```

**ì„ íƒí•œ 22ê°œ ì»¬ëŸ¼ì˜ ì˜ë¯¸**:
- **ì£¼ë¬¸ ê´€ë ¨**: ì£¼ë¬¸ì¼ì, ì£¼ë¬¸_ì´ì•¡, ìˆ˜ëŸ‰, ë‹¨ê°€
- **ë°°ì†¡ ê´€ë ¨**: ì•½ì†_ë°°ì†¡ì‹œê°„, ì‹¤ì œ_ë°°ì†¡ì‹œê°„, ë°°ì†¡_ì†Œìš”ì‹œê°„_ë¶„, ë°°ì†¡ìƒíƒœ, ì§€ì—°_ì‚¬ìœ , ê±°ë¦¬_km
- **ìƒí’ˆ ê´€ë ¨**: ìƒí’ˆëª…, ì¹´í…Œê³ ë¦¬, ë¸Œëœë“œ, ê°€ê²©, ë§ˆì§„ìœ¨_í¼ì„¼íŠ¸, ìœ í†µê¸°í•œ_ì¼ìˆ˜
- **ê³ ê° ê´€ë ¨**: ì§€ì—­, ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸, ì´_ì£¼ë¬¸ìˆ˜, í‰ê· _ì£¼ë¬¸ê¸ˆì•¡
- **ê¸°íƒ€**: ê°ì„±

**Cell 11**: ì£¼ë¬¸ì¼ì ë¶„í¬ í™•ì¸
- ì–´ë–¤ ë‚ ì§œì— ì£¼ë¬¸ì´ ì§‘ì¤‘ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸

---

## 2ë‹¨ê³„: ì›ë³¸ ë°ì´í„° ì†ŒìŠ¤ë³„ ë³‘í•©

### Cell 12: 7ê°œ ì›ë³¸ ë°ì´í„° í†µí•©

ì´ ë‹¨ê³„ëŠ” **ê°€ì¥ í•µì‹¬ì ì¸ ë°ì´í„° ë³‘í•© ê³¼ì •**ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í†µí•©í•©ë‹ˆë‹¤.

#### 2.1 ë°ì´í„° ë¡œë“œ
```python
df_feedback = pd.read_csv(r'data\blinkit_customer_feedback.csv')
df_customers = pd.read_csv(r'data\blinkit_customers.csv')
df_delivery = pd.read_csv(r'data\blinkit_delivery_performance.csv')
df_inventory = pd.read_csv(r'data\blinkit_inventory.csv')
df_orders = pd.read_csv(r'data\blinkit_orders.csv')
df_order_items = pd.read_csv(r'data\blinkit_order_items.csv')
df_products = pd.read_csv(r'data\blinkit_products.csv')
```

#### 2.2 ë‹¨ê³„ë³„ ë³‘í•© ì „ëµ

**A. ì£¼ë¬¸ ìƒì„¸ + ìƒí’ˆ ì •ë³´ ê²°í•©**
```python
df_merged = pd.merge(df_order_items, df_products, on='product_id', how='left')
```
- **ë³‘í•© í‚¤**: `product_id`
- **ë³‘í•© ë°©ì‹**: `left` (ì£¼ë¬¸ ìƒì„¸ ê¸°ì¤€)
- **ì¶”ê°€ë˜ëŠ” ì •ë³´**: ìƒí’ˆëª…, ì¹´í…Œê³ ë¦¬, ë¸Œëœë“œ, ê°€ê²©, ìœ í†µê¸°í•œ ë“±

**B. ì£¼ë¬¸ ê¸°ë³¸ ì •ë³´ ê²°í•©**
```python
df_merged = pd.merge(df_merged, df_orders, on='order_id', how='left')
```
- **ë³‘í•© í‚¤**: `order_id`
- **ì¶”ê°€ë˜ëŠ” ì •ë³´**: ì£¼ë¬¸ì¼ì‹œ, ì‹¤ì œ_ë°°ì†¡ì¼ì‹œ, ì£¼ë¬¸_ì´ì•¡, ë°°ì†¡ìƒíƒœ, ê³ ê°_ID, ë§¤ì¥_ID

**C. ë°°ì†¡ ì„±ê³¼ ë° ê³ ê° ì •ë³´ ê²°í•©**
```python
df_merged = pd.merge(df_merged, df_delivery[['order_id', 'delivery_time_minutes']], 
                     on='order_id', how='left')
df_merged = pd.merge(df_merged, df_customers[['customer_id', 'area', 'customer_segment']], 
                     on='customer_id', how='left')
```
- **ë°°ì†¡ ì„±ê³¼**: `delivery_time_minutes` (ë°°ì†¡ ì†Œìš” ì‹œê°„, ë¶„ ë‹¨ìœ„)
- **ê³ ê° ì •ë³´**: `area` (ì§€ì—­), `customer_segment` (ê³ ê° ì„¸ê·¸ë¨¼íŠ¸)

**D. ê³ ê° í”¼ë“œë°± ê²°í•©**
```python
df_merged = pd.merge(df_merged, df_feedback[['order_id', 'rating', 'feedback_category']], 
                     on='order_id', how='left')
```
- **ì¶”ê°€ë˜ëŠ” ì •ë³´**: 
  - `rating`: í‰ì  (1-5ì )
  - `feedback_category`: í”¼ë“œë°± ì¹´í…Œê³ ë¦¬ (Delivery, App Experience ë“±)

**E. ì¬ê³  ì •ë³´ ê²°í•© (ë‚ ì§œ í¬ë§· í†µì¼ ì‘ì—… í¬í•¨)**
```python
# ì£¼ë¬¸ ë‚ ì§œë¥¼ ì¬ê³  ë°ì´í„° í˜•ì‹(DD-MM-YYYY)ì— ë§ì¶¤
df_merged['order_date_only'] = pd.to_datetime(df_merged['order_date']).dt.strftime('%d-%m-%Y')
df_final = pd.merge(df_merged, df_inventory, 
                    left_on=['product_id', 'order_date_only'], 
                    right_on=['product_id', 'date'], how='left')
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- ì¬ê³  ë°ì´í„°ì˜ ë‚ ì§œ í˜•ì‹ì´ `DD-MM-YYYY` (ì˜ˆ: 17-03-2023)
- ì£¼ë¬¸ ë°ì´í„°ì˜ ë‚ ì§œ í˜•ì‹ì´ `YYYY-MM-DD HH:MM:SS` (ì˜ˆ: 2024-07-17 08:34:01)
- ë”°ë¼ì„œ ì£¼ë¬¸ ë‚ ì§œì—ì„œ ë‚ ì§œ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ì—¬ `DD-MM-YYYY` í˜•ì‹ìœ¼ë¡œ ë³€í™˜
- `product_id`ì™€ ë‚ ì§œë¥¼ ëª¨ë‘ ë§¤ì¹­í•˜ì—¬ í•´ë‹¹ ìƒí’ˆì˜ í•´ë‹¹ ë‚ ì§œ ì¬ê³  ì •ë³´ë¥¼ ê°€ì ¸ì˜´

**ì¶”ê°€ë˜ëŠ” ì¬ê³  ì •ë³´**:
- `stock_received`: ì…ê³ ìˆ˜ëŸ‰
- `damaged_stock`: íŒŒì†ìˆ˜ëŸ‰

#### 2.3 ì»¬ëŸ¼ ì„ íƒ ë° í•œê¸€í™”

**ì»¬ëŸ¼ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬**:
```python
column_mapping = {
    'rating': 'í‰ì ',
    'feedback_category': 'í”¼ë“œë°±_ì¹´í…Œê³ ë¦¬',
    'area': 'area',
    'customer_segment': 'customer_segment',
    'delivery_time_minutes': 'ë°°ì†¡ì†Œìš”_ë¶„',
    'date': 'ê¸°ì¤€ì¼',
    'stock_received': 'ì…ê³ ìˆ˜ëŸ‰',
    'damaged_stock': 'íŒŒì†ìˆ˜ëŸ‰',
    'order_date': 'ì£¼ë¬¸ì¼ì‹œ',
    'actual_delivery_time': 'ì‹¤ì œ_ë°°ì†¡ì¼ì‹œ',
    'order_total': 'ì£¼ë¬¸_ì´ì•¡',
    'delivery_status': 'ë°°ì†¡ìƒíƒœ',
    'store_id': 'store_id',
    'quantity': 'ì£¼ë¬¸_ìˆ˜ëŸ‰',
    'unit_price': 'ë‹¨ê°€',
    'product_name': 'ìƒí’ˆëª…',
    'category': 'ì¹´í…Œê³ ë¦¬',
    'brand': 'ë¸Œëœë“œ',
    'price': 'íŒë§¤ê°€',
    'shelf_life_days': 'ìœ í†µê¸°í•œ_ì¼ìˆ˜',
    'min_stock_level': 'ìµœì†Œ_ì¬ê³ ìˆ˜ì¤€',
    'max_stock_level': 'ìµœëŒ€_ì¬ê³ ìˆ˜ì¤€'
}
```

**ìµœì¢… ê²°ê³¼**: `df_first` (5,000í–‰, 22ì»¬ëŸ¼)

---

## 3ë‹¨ê³„: ì¬ê³  ë°ì´í„° ë³„ë„ ì²˜ë¦¬

### Cell 24-26: ì¬ê³ +ìƒí’ˆ ì •ë³´ ë³‘í•©

**ëª©ì **: ì¬ê³  ë°ì´í„°ë¥¼ ë³„ë„ë¡œ ì²˜ë¦¬í•˜ì—¬ ì¬ê³  ë¶„ì„ì— í™œìš©í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ì…‹ ìƒì„±

**ì²˜ë¦¬ ê³¼ì •**:
```python
# 1. ì¬ê³  ë°ì´í„°ì™€ ìƒí’ˆ ì •ë³´ ë³‘í•©
df_stock = pd.merge(df_inventory, df_products, on='product_id', how='left')

# 2. í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
df_stock = df_stock[[
    'product_id', 'date', 'stock_received', 'damaged_stock', 
    'product_name', 'category', 'brand', 'price', 
    'shelf_life_days', 'min_stock_level', 'max_stock_level'
]]

# 3. í•œê¸€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½
df_stock.columns = [
    'ìƒí’ˆ_ID', 'ê¸°ì¤€ì¼', 'ì…ê³ ìˆ˜ëŸ‰', 'íŒŒì†ìˆ˜ëŸ‰', 
    'ìƒí’ˆëª…', 'ì¹´í…Œê³ ë¦¬', 'ë¸Œëœë“œ', 'íŒë§¤ê°€', 
    'ìœ í†µê¸°í•œ_ì¼ìˆ˜', 'ìµœì†Œ_ì¬ê³ ìˆ˜ì¤€', 'ìµœëŒ€_ì¬ê³ ìˆ˜ì¤€'
]
```

**ê²°ê³¼**: `df_stock` (75,172í–‰, 11ì»¬ëŸ¼)
- ì¼ë³„ ì¬ê³  ê¸°ë¡ì— ìƒí’ˆ ìƒì„¸ ì •ë³´ê°€ ê²°í•©ëœ ë°ì´í„°
- ì¬ê³  ë¶„ì„, ì…ê³ ëŸ‰ ë¶„ì„ ë“±ì— í™œìš© ê°€ëŠ¥

---

## 4ë‹¨ê³„: ì£¼ë¬¸ ë°ì´í„° ì¬êµ¬ì„±

### Cell 30: ë°°ì†¡ì‹œê°„ ê³„ì‚°

**ëª©ì **: ì‹¤ì œ ë°°ì†¡ ì†Œìš” ì‹œê°„ì„ ê³„ì‚°í•˜ì—¬ ìƒˆë¡œìš´ í”¼ì²˜ ìƒì„±

**ê³„ì‚° ê³¼ì •**:
```python
# 1. ë‚ ì§œ í˜•ì‹ ë³€í™˜
df_order_merged['order_date'] = pd.to_datetime(df_order_merged['order_date'])
df_order_merged['actual_delivery_time'] = pd.to_datetime(df_order_merged['actual_delivery_time'])

# 2. ë°°ì†¡ì‹œê°„ ê³„ì‚° (ë¶„ ë‹¨ìœ„)
df_order_merged['ë°°ì†¡ì‹œê°„'] = (df_order_merged['actual_delivery_time'] - 
                              df_order_merged['order_date']).dt.total_seconds() / 60
```

**ìƒì„±ë˜ëŠ” ë³€ìˆ˜**:
- `ë°°ì†¡ì‹œê°„`: ì‹¤ì œ ë°°ì†¡ ì†Œìš” ì‹œê°„ (ë¶„)
- `delivery_time_minutes`: ë°°ì†¡ ì§€ì—° ì‹œê°„ (ì•½ì† ì‹œê°„ ëŒ€ë¹„, ìŒìˆ˜ë©´ ì¡°ê¸° ë°°ì†¡)

**ì°¨ì´ì **:
- `ë°°ì†¡ì‹œê°„`: ì£¼ë¬¸ë¶€í„° ë°°ì†¡ ì™„ë£Œê¹Œì§€ì˜ ì‹¤ì œ ì†Œìš” ì‹œê°„
- `ë°°ì†¡ì§€ì—°ì‹œê°„`: ì•½ì† ì‹œê°„ ëŒ€ë¹„ ì–¼ë§ˆë‚˜ ë¹¨ë¦¬/ëŠ¦ê²Œ ë°°ì†¡ë˜ì—ˆëŠ”ì§€

### Cell 38-40: ë‹¨ê³„ë³„ ë³‘í•©

**Step 1 (Cell 38)**: ì£¼ë¬¸ ìƒì„¸ + ë°°ì†¡ ì§€ì—°ì‹œê°„
```python
df_step1 = pd.merge(
    df_items, 
    df_delivery[['order_id', 'delivery_time_minutes']], 
    on='order_id', 
    how='left'
)
```
- ì£¼ë¬¸ ìƒì„¸ì— ë°°ì†¡ ì§€ì—° ì‹œê°„ ì¶”ê°€
- ì»¬ëŸ¼ëª… í•œê¸€í™”: `delivery_time_minutes` â†’ `ë°°ì†¡_ì§€ì—°ì‹œê°„`

**Step 2 (Cell 40)**: í”¼ë“œë°± ë°ì´í„° ì¶”ê°€
```python
df_step2 = pd.merge(
    df_step1,
    df_feedback[['order_id', 'rating']],
    left_on='ì£¼ë¬¸_ID',
    right_on='order_id',
    how='left'
)
```
- í‰ì (`rating`) ì •ë³´ ì¶”ê°€
- ì¤‘ë³µëœ `order_id` ì»¬ëŸ¼ ì œê±°

**Step 3 (Cell 41)**: ì£¼ë¬¸ ê¸°ë³¸ ì •ë³´ ì¶”ê°€
```python
# ë°°ì†¡ì†Œìš”ì‹œê°„ ê³„ì‚°
df_orders['ë°°ì†¡ì†Œìš”ì‹œê°„'] = (df_orders['actual_delivery_time'] - 
                          df_orders['order_date']).dt.total_seconds() / 60

# ì£¼ë¬¸ë‚ ì§œ ì¶”ì¶œ (ì‹œê°„ ì •ë³´ ì œì™¸)
df_orders['ì£¼ë¬¸ë‚ ì§œ'] = df_orders['order_date'].dt.date

# ë³‘í•©
df_step3 = pd.merge(df_step2, df_orders_subset, on='ì£¼ë¬¸_ID', how='left')
```

**ì¶”ê°€ë˜ëŠ” ì •ë³´**:
- `ê³ ê°_ID`: ê³ ê° ì‹ë³„ì
- `ë°°ì†¡ì†Œìš”ì‹œê°„`: ì‹¤ì œ ë°°ì†¡ ì†Œìš” ì‹œê°„
- `ì£¼ë¬¸ë‚ ì§œ`: ë‚ ì§œë§Œ ì¶”ì¶œ (ì‹œê°„ ì œì™¸)

### Cell 45: ìƒí’ˆ ë° ê³ ê° ì •ë³´ ì¶”ê°€

**ìƒí’ˆ ì •ë³´ ë³‘í•©**:
```python
df_prod_subset = df_products[['product_id', 'product_name', 'category', 
                              'brand', 'shelf_life_days']].rename(columns={
    'product_id': 'ìƒí’ˆ_ID',
    'product_name': 'ìƒí’ˆëª…',
    'category': 'ì¹´í…Œê³ ë¦¬',
    'brand': 'ë¸Œëœë“œ',
    'shelf_life_days': 'ìœ í†µê¸°í•œ_ì¼ìˆ˜'
})
df_step4 = pd.merge(df_step3, df_prod_subset, on='ìƒí’ˆ_ID', how='left')
```

**ê³ ê° ì •ë³´ ë³‘í•©**:
```python
df_cust_subset = df_customers[['customer_id', 'area', 'customer_segment']].rename(columns={
    'customer_id': 'ê³ ê°_ID',
    'area': 'ì§€ì—­',
    'customer_segment': 'íšŒì›íƒ€ì…'
})
df_step5 = pd.merge(df_step4, df_cust_subset, on='ê³ ê°_ID', how='left')
```

**ìµœì¢… ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬**:
```python
df_step5 = df_step5[['ì£¼ë¬¸_ID', 'ê³ ê°_ID', 'ì£¼ë¬¸ë‚ ì§œ', 'ìƒí’ˆ_ID', 'ìƒí’ˆëª…', 
                     'ì¹´í…Œê³ ë¦¬', 'ë¸Œëœë“œ', 'ìœ í†µê¸°í•œ_ì¼ìˆ˜', 'ì§€ì—­', 'íšŒì›íƒ€ì…', 
                     'ê¸ˆì•¡', 'ë°°ì†¡_ì§€ì—°ì‹œê°„', 'ë°°ì†¡ì†Œìš”ì‹œê°„', 'ìˆ˜ëŸ‰', 'í‰ì ']]
```

**ê²°ê³¼**: `df_step5` (5,000í–‰, 15ì»¬ëŸ¼)

---

## 5ë‹¨ê³„: ìµœì¢… ë°ì´í„°ì…‹ ìƒì„±

### Cell 48: ID ì»¬ëŸ¼ ì œê±°

**ëª©ì **: ë¶„ì„ì— ë¶ˆí•„ìš”í•œ ì‹ë³„ì ì œê±°

```python
df_final = df_step5.drop(columns=['ì£¼ë¬¸_ID','ê³ ê°_ID'])
```

**ì œê±° ì´ìœ **:
- `ì£¼ë¬¸_ID`, `ê³ ê°_ID`ëŠ” ì‹ë³„ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©ë˜ë©° ë¶„ì„ì—ëŠ” ë¶ˆí•„ìš”
- ê°œì¸ì •ë³´ ë³´í˜¸ ì¸¡ë©´ì—ì„œë„ ì œê±°í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ

**ê²°ê³¼**: 13ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ì¶•ì†Œ

### Cell 52: ìƒí’ˆë³„ í‰ê·  í‰ì  ê³„ì‚°

**ëª©ì **: ê° ìƒí’ˆì˜ ì „ì²´ì ì¸ í‰ì  ìˆ˜ì¤€ì„ íŒŒì•…í•˜ê¸° ìœ„í•œ ì§‘ê³„ ë³€ìˆ˜ ìƒì„±

**ê³„ì‚° ê³¼ì •**:
```python
# 1. ìƒí’ˆ_IDë³„ë¡œ í‰ê·  í‰ì  ê³„ì‚°
product_avg_rating = df_final.groupby('ìƒí’ˆ_ID')['í‰ì '].mean().round(2).reset_index()

# 2. ì»¬ëŸ¼ëª… ë³€ê²½
product_avg_rating.columns = ['ìƒí’ˆ_ID', 'ìƒí’ˆë³„_í‰ê· í‰ì ']

# 3. ì›ë³¸ ë°ì´í„°ì— ë³‘í•©
df_final1 = pd.merge(df_final, product_avg_rating, on='ìƒí’ˆ_ID', how='left')
```

**ìƒì„±ë˜ëŠ” ë³€ìˆ˜**:
- `ìƒí’ˆë³„_í‰ê· í‰ì `: í•´ë‹¹ ìƒí’ˆì˜ ëª¨ë“  ì£¼ë¬¸ì— ëŒ€í•œ í‰ê·  í‰ì 
- ê°œë³„ ì£¼ë¬¸ì˜ í‰ì ê³¼ ë¹„êµí•˜ì—¬ í•´ë‹¹ ì£¼ë¬¸ì´ í‰ê· ë³´ë‹¤ ë†’ì€ì§€ ë‚®ì€ì§€ íŒë‹¨ ê°€ëŠ¥

**í™œìš© ì˜ˆì‹œ**:
- íŠ¹ì • ì£¼ë¬¸ì˜ í‰ì ì´ ìƒí’ˆë³„ í‰ê· ë³´ë‹¤ ë‚®ìœ¼ë©´ â†’ íŠ¹ë³„í•œ ë¬¸ì œê°€ ìˆì—ˆì„ ê°€ëŠ¥ì„±
- ìƒí’ˆë³„ í‰ê·  í‰ì ì´ ë‚®ì€ ìƒí’ˆ â†’ í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•œ ìƒí’ˆ

### Cell 58: ìµœì¢… ë°ì´í„° ì €ì¥

```python
df_final1.to_csv(r'data\merged_data\blinkit_final_data.csv', 
                 index=False, encoding='utf-8-sig')
```

**ì €ì¥ë˜ëŠ” ì •ë³´**:
- **íŒŒì¼ëª…**: `blinkit_final_data.csv`
- **ì¸ì½”ë”©**: `utf-8-sig` (í•œê¸€ ê¹¨ì§ ë°©ì§€)
- **ì¸ë±ìŠ¤**: ì €ì¥í•˜ì§€ ì•ŠìŒ (`index=False`)

**ìµœì¢… ë°ì´í„° êµ¬ì¡°**:
- **í–‰ ìˆ˜**: 5,000í–‰
- **ì»¬ëŸ¼ ìˆ˜**: 14ê°œ
  - ì£¼ë¬¸ë‚ ì§œ, ìƒí’ˆ_ID, ìƒí’ˆëª…, ì¹´í…Œê³ ë¦¬, ë¸Œëœë“œ, ìœ í†µê¸°í•œ_ì¼ìˆ˜
  - ì§€ì—­, íšŒì›íƒ€ì…, ê¸ˆì•¡, ë°°ì†¡_ì§€ì—°ì‹œê°„, ë°°ì†¡ì†Œìš”ì‹œê°„, ìˆ˜ëŸ‰
  - í‰ì , ìƒí’ˆë³„_í‰ê· í‰ì 

---

## 6ë‹¨ê³„: ìƒê´€ê´€ê³„ ë¶„ì„

### Cell 61: ì „ì²´ ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„

**ëª©ì **: ë³€ìˆ˜ë“¤ ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ì—¬ ëª¨ë¸ë§ì— í™œìš©í•  ì¤‘ìš”í•œ ë³€ìˆ˜ ì‹ë³„

#### 6.1 Label Encoding

**ì´ìœ **: ë²”ì£¼í˜• ë³€ìˆ˜(ë¬¸ìì—´)ëŠ” ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ìˆ«ìë¡œ ë³€í™˜

```python
cols_to_encode = ['ì¹´í…Œê³ ë¦¬', 'ë¸Œëœë“œ', 'ìƒí’ˆëª…', 'íšŒì›íƒ€ì…', 'ì§€ì—­']
le = LabelEncoder()
for col in cols_to_encode:
    df_label[col] = le.fit_transform(df_label[col].astype(str))
```

**ë³€í™˜ ê³¼ì •**:
- ê° ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê³ ìœ ê°’ì„ 0, 1, 2, ... ìˆ«ìë¡œ ë§¤í•‘
- ì˜ˆ: 'Regular' â†’ 0, 'Premium' â†’ 1, 'New' â†’ 2

#### 6.2 ìƒê´€ê´€ê³„ í–‰ë ¬ ê³„ì‚°

```python
corr_matrix = df_label.drop(columns=['ì£¼ë¬¸ë‚ ì§œ']).corr()
```

**ì œì™¸í•˜ëŠ” ì»¬ëŸ¼**: `ì£¼ë¬¸ë‚ ì§œ` (ë‚ ì§œëŠ” ìƒê´€ê³„ìˆ˜ ê³„ì‚°ì— ë¶€ì í•©)

#### 6.3 íˆíŠ¸ë§µ ì‹œê°í™”

```python
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Correlation Heatmap (Label Encoded)', fontsize=15)
plt.show()
```

**íˆíŠ¸ë§µ í•´ì„**:
- **ë¹¨ê°„ìƒ‰**: ì–‘ì˜ ìƒê´€ê´€ê³„ (ê°’ì´ í´ìˆ˜ë¡ ê°•í•œ ì–‘ì˜ ìƒê´€)
- **íŒŒë€ìƒ‰**: ìŒì˜ ìƒê´€ê´€ê³„
- **í°ìƒ‰**: ìƒê´€ê´€ê³„ ì—†ìŒ (0ì— ê°€ê¹Œì›€)

#### 6.4 ìˆ˜ëŸ‰ ë° ê¸ˆì•¡ ê¸°ì¤€ ìƒê´€ê³„ìˆ˜ í™•ì¸

```python
print(corr_matrix[['ìˆ˜ëŸ‰', 'ê¸ˆì•¡']].sort_values(by='ìˆ˜ëŸ‰', ascending=False))
```

**ë¶„ì„ ëª©ì **:
- ìˆ˜ëŸ‰(íŒë§¤ëŸ‰)ê³¼ ê°€ì¥ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ë³€ìˆ˜ íŒŒì•…
- ê¸ˆì•¡(ë§¤ì¶œ)ê³¼ ê°€ì¥ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ë³€ìˆ˜ íŒŒì•…
- ì´ë¥¼ í†µí•´ ìˆ˜ìš” ì˜ˆì¸¡ì— ì¤‘ìš”í•œ ë³€ìˆ˜ ì‹ë³„

---

## 7ë‹¨ê³„: ì‹œê³„ì—´ í”¼ì²˜ ìƒì„±

### Cell 62-65: ì¼ë³„ ì§‘ê³„ ë° ì‹œê³„ì—´ ë³€ìˆ˜ ìƒì„±

**ëª©ì **: ì‹œê³„ì—´ ë¶„ì„ì„ ìœ„í•œ ì¼ë³„ ë°ì´í„°ë¡œ ë³€í™˜í•˜ê³ , ê³¼ê±° ë°ì´í„°ë¥¼ í™œìš©í•œ í”¼ì²˜ ìƒì„±

#### 7.1 ì¼ë³„ ì§‘ê³„ (Daily Aggregation)

```python
df_daily = df.groupby(['ì£¼ë¬¸ë‚ ì§œ', 'ìƒí’ˆëª…']).agg({
    'ìˆ˜ëŸ‰': 'sum',           # ì¼ì¼ ì´ íŒë§¤ëŸ‰
    'ê¸ˆì•¡': 'sum',           # ì¼ì¼ ì´ ë§¤ì¶œ
    'í‰ì ': 'mean',          # ì¼ì¼ í‰ê·  í‰ì 
    'ë°°ì†¡ì†Œìš”ì‹œê°„': 'mean',   # ì¼ì¼ í‰ê·  ë°°ì†¡ì‹œê°„
    'ì¹´í…Œê³ ë¦¬': 'first',     # ë²”ì£¼í˜• ì •ë³´ ìœ ì§€
    'ë¸Œëœë“œ': 'first'
}).reset_index().sort_values(['ìƒí’ˆëª…', 'ì£¼ë¬¸ë‚ ì§œ'])
```

**ì§‘ê³„ ë°©ì‹**:
- **ê·¸ë£¹í™” ê¸°ì¤€**: `ì£¼ë¬¸ë‚ ì§œ` + `ìƒí’ˆëª…`
  - ê°™ì€ ë‚  ê°™ì€ ìƒí’ˆì˜ ì—¬ëŸ¬ ì£¼ë¬¸ì„ í•˜ë‚˜ë¡œ í•©ì¹¨
- **ì§‘ê³„ í•¨ìˆ˜**:
  - `sum`: ìˆ˜ëŸ‰, ê¸ˆì•¡ (í•©ê³„)
  - `mean`: í‰ì , ë°°ì†¡ì†Œìš”ì‹œê°„ (í‰ê· )
  - `first`: ì¹´í…Œê³ ë¦¬, ë¸Œëœë“œ (ì²« ë²ˆì§¸ ê°’, ëª¨ë‘ ë™ì¼í•˜ë¯€ë¡œ)

**ê²°ê³¼**: ì¼ë³„ ìƒí’ˆë³„ ë°ì´í„°ë¡œ ë³€í™˜

#### 7.2 Lag ë³€ìˆ˜ ìƒì„±

**Lag ë³€ìˆ˜ë€?**: ê³¼ê±° ì‹œì ì˜ ë°ì´í„°ë¥¼ í˜„ì¬ ì‹œì ì— í”¼ì²˜ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒ

```python
for lag in [1, 7]:  # 1ì¼ ì „, 7ì¼ ì „(ì „ì£¼) ë°ì´í„°
    # íŒë§¤ëŸ‰ Lag
    df_daily[f'ìˆ˜ëŸ‰_lag_{lag}'] = df_daily.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(lag)
    # í‰ì  Lag
    df_daily[f'í‰ì _lag_{lag}'] = df_daily.groupby('ìƒí’ˆëª…')['í‰ì '].shift(lag)
```

**ìƒì„±ë˜ëŠ” ë³€ìˆ˜**:
- `ìˆ˜ëŸ‰_lag_1`: ì–´ì œì˜ íŒë§¤ëŸ‰
- `ìˆ˜ëŸ‰_lag_7`: ì§€ë‚œì£¼ ê°™ì€ ìš”ì¼ì˜ íŒë§¤ëŸ‰
- `í‰ì _lag_1`: ì–´ì œì˜ í‰ì 
- `í‰ì _lag_7`: ì§€ë‚œì£¼ ê°™ì€ ìš”ì¼ì˜ í‰ì 

**shift() í•¨ìˆ˜ì˜ ë™ì‘**:
- `shift(1)`: í•œ í–‰ì”© ì•„ë˜ë¡œ ì´ë™ (ê³¼ê±° ë°ì´í„°)
- `groupby('ìƒí’ˆëª…')`: ê° ìƒí’ˆë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ shift ìˆ˜í–‰

**ì˜ˆì‹œ**:
```
ìƒí’ˆëª…    ì£¼ë¬¸ë‚ ì§œ     ìˆ˜ëŸ‰    ìˆ˜ëŸ‰_lag_1
A        2024-01-01   10      NaN
A        2024-01-02   15      10    â† ì–´ì œì˜ ìˆ˜ëŸ‰
A        2024-01-03   12      15    â† ì–´ì œì˜ ìˆ˜ëŸ‰
```

#### 7.3 ë³€í™”ëŸ‰ ê³„ì‚°

```python
# ì¦ê°€ëŸ‰ ê³„ì‚°
df_daily['ì£¼ë¬¸_ì¦ê°€ëŸ‰'] = df_daily['ìˆ˜ëŸ‰'] - df_daily['ìˆ˜ëŸ‰_lag_1']

# í‰ì  ë³€í™” ê³„ì‚°
df_daily['í‰ì _ë³€í™”'] = df_daily['í‰ì '] - df_daily['í‰ì _lag_1']
```

**ìƒì„±ë˜ëŠ” ë³€ìˆ˜**:
- `ì£¼ë¬¸_ì¦ê°€ëŸ‰`: ì „ì¼ ëŒ€ë¹„ íŒë§¤ëŸ‰ ì¦ê°€/ê°ì†ŒëŸ‰
  - ì–‘ìˆ˜: ì¦ê°€
  - ìŒìˆ˜: ê°ì†Œ
- `í‰ì _ë³€í™”`: ì „ì¼ ëŒ€ë¹„ í‰ì  ë³€í™”
  - ì–‘ìˆ˜: í‰ì  ìƒìŠ¹
  - ìŒìˆ˜: í‰ì  í•˜ë½

#### 7.4 ê²°ì¸¡ì¹˜ ì œê±°

```python
df_daily = df_daily.dropna()
```

**ê²°ì¸¡ì¹˜ ë°œìƒ ì´ìœ **:
- Lag ë³€ìˆ˜ ìƒì„± ì‹œ ì²« ë²ˆì§¸ í–‰ì—ëŠ” ê³¼ê±° ë°ì´í„°ê°€ ì—†ì–´ì„œ NaN ë°œìƒ
- ì˜ˆ: ì²« ë‚ ì§œì˜ ë°ì´í„°ëŠ” `ìˆ˜ëŸ‰_lag_1`ì´ ì—†ìŒ

**ê²°ê³¼**: 4,181í–‰ (ì›ë³¸ 5,000í–‰ì—ì„œ ê²°ì¸¡ì¹˜ ì œê±° í›„)

#### 7.5 ë°ì´í„° ì €ì¥

```python
df_daily.to_csv(r'data\merged_data\blinkit_daily_data.csv', 
                index=False, encoding='utf-8-sig')
```

**ì €ì¥ë˜ëŠ” ë°ì´í„°**:
- **íŒŒì¼ëª…**: `blinkit_daily_data.csv`
- **í–‰ ìˆ˜**: 4,181í–‰
- **ì»¬ëŸ¼ ìˆ˜**: 14ê°œ
  - ê¸°ë³¸ ì»¬ëŸ¼: ì£¼ë¬¸ë‚ ì§œ, ìƒí’ˆëª…, ìˆ˜ëŸ‰, ê¸ˆì•¡, í‰ì , ë°°ì†¡ì†Œìš”ì‹œê°„, ì¹´í…Œê³ ë¦¬, ë¸Œëœë“œ
  - Lag ë³€ìˆ˜: ìˆ˜ëŸ‰_lag_1, ìˆ˜ëŸ‰_lag_7, í‰ì _lag_1, í‰ì _lag_7
  - ë³€í™”ëŸ‰: ì£¼ë¬¸_ì¦ê°€ëŸ‰, í‰ì _ë³€í™”

---

## 8ë‹¨ê³„: ê¸°ë³¸ ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸

### Cell 67: ê°„ë‹¨í•œ Random Forest ëª¨ë¸

**ëª©ì **: ê¸°ë³¸ì ì¸ ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶• ë° ì„±ëŠ¥ í™•ì¸

#### 8.1 í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§

```python
# Lag ë³€ìˆ˜ ìƒì„±
df_daily['ìˆ˜ëŸ‰_lag_1'] = df_daily.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(1)
df_daily['ìˆ˜ëŸ‰_lag_7'] = df_daily.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(7)

# ë³€í™”ëŸ‰ ê³„ì‚°
df_daily['ì£¼ë¬¸_ì¦ê°€ëŸ‰'] = df_daily['ìˆ˜ëŸ‰_lag_1'] - df_daily.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(2)
df_daily['í‰ì _ë³€í™”'] = df_daily['í‰ì '] - df_daily.groupby('ìƒí’ˆëª…')['í‰ì '].shift(1)

# ë‚ ì§œ í”¼ì²˜ ì¶”ì¶œ
df_daily['month'] = df_daily['ì£¼ë¬¸ë‚ ì§œ'].dt.month
df_daily['day_of_week'] = df_daily['ì£¼ë¬¸ë‚ ì§œ'].dt.dayofweek
```

**ìƒì„±ë˜ëŠ” í”¼ì²˜**:
- **ì‹œê³„ì—´ í”¼ì²˜**: ìˆ˜ëŸ‰_lag_1, ìˆ˜ëŸ‰_lag_7, ì£¼ë¬¸_ì¦ê°€ëŸ‰, í‰ì _ë³€í™”
- **ë‚ ì§œ í”¼ì²˜**: month (ì›”), day_of_week (ìš”ì¼, 0=ì›”ìš”ì¼)

#### 8.2 ì¸ì½”ë”©

```python
le = LabelEncoder()
for col in ['ìƒí’ˆëª…', 'ì¹´í…Œê³ ë¦¬', 'ë¸Œëœë“œ']:
    df_model[col] = le.fit_transform(df_model[col].astype(str))
```

**ì¸ì½”ë”© ì´ìœ **: Random Forest ëª¨ë¸ì€ ìˆ«ìí˜• ë°ì´í„°ë§Œ ì…ë ¥ë°›ì„ ìˆ˜ ìˆìŒ

#### 8.3 ëª¨ë¸ í•™ìŠµ

```python
# í”¼ì²˜ ë° íƒ€ê²Ÿ ì„¤ì •
X = df_model[['ìƒí’ˆëª…', 'ì¹´í…Œê³ ë¦¬', 'ë¸Œëœë“œ', 'month', 'day_of_week', 
              'ìˆ˜ëŸ‰_lag_1', 'ìˆ˜ëŸ‰_lag_7', 'ì£¼ë¬¸_ì¦ê°€ëŸ‰', 'í‰ì _ë³€í™”', 'ë°°ì†¡ì†Œìš”ì‹œê°„']]
y = df_model['ìˆ˜ëŸ‰']

# ë°ì´í„° ë¶„í•  (8:2)
split = int(len(X) * 0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# ëª¨ë¸ í•™ìŠµ
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
```

**ëª¨ë¸ íŒŒë¼ë¯¸í„°**:
- `n_estimators=100`: ì˜ì‚¬ê²°ì • ë‚˜ë¬´ 100ê°œ ì‚¬ìš©
- `random_state=42`: ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ê³ ì •

**ì„±ëŠ¥ ì§€í‘œ**:
- **MAE (Mean Absolute Error)**: 0.85ê°œ
  - í‰ê· ì ìœ¼ë¡œ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ê°€ 0.85ê°œ

### Cell 69: ê³ ë„í™”ëœ ëª¨ë¸

#### 9.1 ì¶”ê°€ í”¼ì²˜ ìƒì„±

```python
# (1) ë‚ ì§œ ê´€ë ¨ ë³€ìˆ˜
df_daily['month'] = df_daily['ì£¼ë¬¸ë‚ ì§œ'].dt.month
df_daily['day_of_week'] = df_daily['ì£¼ë¬¸ë‚ ì§œ'].dt.dayofweek
df_daily['is_weekend'] = df_daily['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)

# (2) ì‹œê³„ì—´ Lag ë³€ìˆ˜
df_daily['ìˆ˜ëŸ‰_lag_1'] = df_daily.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(1)
df_daily['ìˆ˜ëŸ‰_lag_7'] = df_daily.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(7)
df_daily['í‰ì _lag_1'] = df_daily.groupby('ìƒí’ˆëª…')['í‰ì '].shift(1)

# (3) ì´ë™ í‰ê·  (ìµœê·¼ 3ì¼ íŒë§¤ íë¦„)
df_daily['ìˆ˜ëŸ‰_MA3'] = df_daily.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].transform(
    lambda x: x.rolling(window=3).mean()
).shift(1)

# (4) ì¦ê°€ëŸ‰ ë° ë³€í™”ìœ¨
df_daily['ì£¼ë¬¸_ì¦ê°€ëŸ‰'] = df_daily['ìˆ˜ëŸ‰_lag_1'] - df_daily.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(2)
df_daily['í‰ì _ë³€í™”'] = df_daily['í‰ì '] - df_daily['í‰ì _lag_1']
```

**ìƒˆë¡œ ì¶”ê°€ëœ í”¼ì²˜**:
- `is_weekend`: ì£¼ë§ ì—¬ë¶€ (0 ë˜ëŠ” 1)
- `ìˆ˜ëŸ‰_MA3`: ìµœê·¼ 3ì¼ ì´ë™í‰ê·  (ë‹¨ê¸° ì¶”ì„¸ íŒŒì•…)

#### 9.2 ëª¨ë¸ í•™ìŠµ ë° í‰ê°€

```python
features = [
    'ìƒí’ˆëª…', 'ì¹´í…Œê³ ë¦¬', 'ë¸Œëœë“œ', 'month', 'day_of_week', 'is_weekend',
    'ìˆ˜ëŸ‰_lag_1', 'ìˆ˜ëŸ‰_lag_7', 'ìˆ˜ëŸ‰_MA3', 'ì£¼ë¬¸_ì¦ê°€ëŸ‰', 'í‰ì _ë³€í™”', 'ë°°ì†¡ì†Œìš”ì‹œê°„'
]

model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)
```

**ëª¨ë¸ íŒŒë¼ë¯¸í„° ë³€ê²½**:
- `n_estimators=200`: ë‚˜ë¬´ ê°œìˆ˜ ì¦ê°€ (ë” ì •í™•í•œ ì˜ˆì¸¡)
- `max_depth=10`: ë‚˜ë¬´ ê¹Šì´ ì œí•œ (ê³¼ì í•© ë°©ì§€)
- `n_jobs=-1`: ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš© (í•™ìŠµ ì†ë„ í–¥ìƒ)

#### 9.3 ì„±ëŠ¥ í‰ê°€

```python
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)
accuracy = (1 - (mae / y_test.mean())) * 100
```

**ì„±ëŠ¥ ì§€í‘œ**:
- **MAE**: 0.86ê°œ
- **RMSE**: 1.08
- **RÂ² Score**: 0.0501 (ì„¤ëª…ë ¥ 5.01%)
- **ì •í™•ë„**: 62.50%

**ì§€í‘œ í•´ì„**:
- **MAE**: í‰ê·  ì˜¤ì°¨ê°€ 0.86ê°œ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
- **RMSE**: í° ì˜¤ì°¨ì— ë” ë¯¼ê°í•œ ì§€í‘œ (1.08)
- **RÂ²**: ëª¨ë¸ì´ ë°ì´í„°ì˜ 5.01%ë¥¼ ì„¤ëª… (ë‚®ìŒ, ê°œì„  í•„ìš”)
- **ì •í™•ë„**: 62.50% (100%ì—ì„œ ì˜¤ì°¨ìœ¨ì„ ëº€ ê°’)

#### 9.4 ë³€ìˆ˜ ì¤‘ìš”ë„ ì‹œê°í™”

```python
importances = model.feature_importances_
plt.figure(figsize=(10, 6))
plt.barh(features, importances)
plt.title('Feature Importances for Demand Forecasting')
plt.xlabel('Importance Value')
plt.show()
```

**ë³€ìˆ˜ ì¤‘ìš”ë„ í•´ì„**:
- ë†’ì€ ì¤‘ìš”ë„: ì˜ˆì¸¡ì— ì¤‘ìš”í•œ ë³€ìˆ˜
- ë‚®ì€ ì¤‘ìš”ë„: ì˜ˆì¸¡ì— ëœ ì¤‘ìš”í•œ ë³€ìˆ˜
- ì´ë¥¼ í†µí•´ ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì œê±° ê°€ëŠ¥

---

## 9ë‹¨ê³„: ë§ˆì¼€íŒ… ë°ì´í„° ê²°í•©

### Cell 70: ë§ˆì¼€íŒ… ë°ì´í„° ë¡œë“œ ë° í™•ì¸

```python
df_marketing = pd.read_csv(r'data\blinkit_marketing_performance.csv')
df_marketing.info()
```

**ë§ˆì¼€íŒ… ë°ì´í„° êµ¬ì¡°**:
- **í–‰ ìˆ˜**: 5,400í–‰
- **ì»¬ëŸ¼ ìˆ˜**: 11ê°œ
  - `campaign_id`: ìº í˜ì¸ ID
  - `campaign_name`: ìº í˜ì¸ëª…
  - `date`: ë‚ ì§œ
  - `target_audience`: íƒ€ê²Ÿ ê³ ê°ì¸µ
  - `channel`: ì±„ë„ (App, Email ë“±)
  - `impressions`: ë…¸ì¶œ ìˆ˜
  - `clicks`: í´ë¦­ ìˆ˜
  - `conversions`: ì „í™˜ ìˆ˜
  - `spend`: ê´‘ê³ ë¹„
  - `revenue_generated`: ë°œìƒ ë§¤ì¶œ
  - `roas`: ê´‘ê³  íˆ¬ì ëŒ€ë¹„ ìˆ˜ìµë¥ 

### Cell 72: ë§ˆì¼€íŒ… ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³‘í•©

#### 9.1 ë§ˆì¼€íŒ… ë°ì´í„° ì§‘ê³„

**ëª©ì **: ê°™ì€ ë‚  ì—¬ëŸ¬ ì±„ë„ì—ì„œ ê´‘ê³ ë¥¼ í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•©ì‚°/í‰ê·  í•„ìš”

```python
df_mkt_agg = df_marketing.groupby(['date', 'target_audience']).agg({
    'spend': 'sum',           # ì´ ê´‘ê³ ë¹„
    'clicks': 'sum',          # ì´ í´ë¦­ìˆ˜
    'impressions': 'sum',     # ì´ ë…¸ì¶œìˆ˜
    'conversions': 'sum',     # ì´ ì „í™˜ìˆ˜
    'roas': 'mean'            # í‰ê·  ROAS
}).reset_index()
```

**ì§‘ê³„ ë°©ì‹**:
- **ê·¸ë£¹í™” ê¸°ì¤€**: `date` + `target_audience`
  - ê°™ì€ ë‚  ê°™ì€ íƒ€ê²Ÿ ê³ ê°ì¸µì˜ ì—¬ëŸ¬ ì±„ë„ ê´‘ê³ ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
- **ì§‘ê³„ í•¨ìˆ˜**:
  - `sum`: spend, clicks, impressions, conversions (í•©ê³„)
  - `mean`: roas (í‰ê· )

#### 9.2 íšŒì›íƒ€ì… ë§¤í•‘

**ë¬¸ì œ**: ì£¼ë¬¸ ë°ì´í„°ì˜ `íšŒì›íƒ€ì…`ê³¼ ë§ˆì¼€íŒ… ë°ì´í„°ì˜ `target_audience` ëª…ì¹­ì´ ë‹¤ë¦„

```python
mapping = {
    'Regular': 'All',
    'Premium': 'Premium',
    'New': 'New Users',
    'Inactive': 'Inactive'
}
df_final['target_audience'] = df_final['íšŒì›íƒ€ì…'].map(mapping)
```

**ë§¤í•‘ ì´ìœ **:
- ì£¼ë¬¸ ë°ì´í„°: `Regular`, `Premium`, `New`, `Inactive`
- ë§ˆì¼€íŒ… ë°ì´í„°: `All`, `Premium`, `New Users`, `Inactive`
- ëª…ì¹­ì„ í†µì¼í•˜ì—¬ ë³‘í•© ê°€ëŠ¥í•˜ë„ë¡ í•¨

#### 9.3 ë°ì´í„° ë³‘í•©

```python
df_with_mkt = pd.merge(
    df_final, 
    df_mkt_agg, 
    left_on=['ì£¼ë¬¸ë‚ ì§œ', 'target_audience'], 
    right_on=['date', 'target_audience'], 
    how='left'
)
```

**ë³‘í•© ê¸°ì¤€**:
- `ì£¼ë¬¸ë‚ ì§œ` = `date`
- `target_audience` = `target_audience`

**ë³‘í•© ë°©ì‹**: `left` (ì£¼ë¬¸ ë°ì´í„° ê¸°ì¤€)
- ì£¼ë¬¸ì´ ìˆì§€ë§Œ ë§ˆì¼€íŒ… í™œë™ì´ ì—†ëŠ” ë‚ ë„ í¬í•¨

#### 9.4 ê²°ì¸¡ì¹˜ ì²˜ë¦¬

```python
df_with_mkt[['spend', 'clicks', 'impressions', 'conversions']] = \
    df_with_mkt[['spend', 'clicks', 'impressions', 'conversions']].fillna(0)
df_with_mkt.drop(columns=['date'], inplace=True)
```

**ì²˜ë¦¬ ë°©ì‹**:
- ë§ˆì¼€íŒ… í™œë™ì´ ì—†ëŠ” ë‚ ì€ 0ìœ¼ë¡œ ì±„ì›€
- ì¤‘ë³µëœ `date` ì»¬ëŸ¼ ì œê±°

**ê²°ê³¼**: `df_with_mkt` (5,000í–‰, 20ì»¬ëŸ¼)
- ê¸°ì¡´ 14ê°œ ì»¬ëŸ¼ + ë§ˆì¼€íŒ… 6ê°œ ì»¬ëŸ¼ (spend, clicks, impressions, conversions, roas, target_audience)

---

## 10ë‹¨ê³„: ë§ˆì¼€íŒ… í¬í•¨ ìˆ˜ìš” ì˜ˆì¸¡

### Cell 79: ë§ˆì¼€íŒ… ë³€ìˆ˜ í¬í•¨ ëª¨ë¸

**ëª©ì **: ë§ˆì¼€íŒ… í™œë™ì´ íŒë§¤ëŸ‰ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„

#### 10.1 ë°ì´í„° ì¤€ë¹„

```python
# ë§ˆì¼€íŒ… ë°ì´í„° ì§‘ê³„
df_mkt_agg = df_marketing.groupby(['date', 'target_audience']).agg({
    'spend': 'sum', 'clicks': 'sum', 'roas': 'mean'
}).reset_index()

# ë°ì´í„° ê²°í•©
df_combined = pd.merge(df_final, df_mkt_agg, 
                       left_on=['ì£¼ë¬¸ë‚ ì§œ', 'target_audience'], 
                       right_on=['date', 'target_audience'], how='left').fillna(0)
```

#### 10.2 ì¼ë³„/ìƒí’ˆë³„ ì‹œê³„ì—´ ë°ì´í„° êµ¬ì„±

```python
df_daily = df_combined.groupby(['ì£¼ë¬¸ë‚ ì§œ', 'ìƒí’ˆëª…']).agg({
    'ìˆ˜ëŸ‰': 'sum', 
    'í‰ì ': 'mean', 
    'spend': 'mean',      # ì¼ì¼ í‰ê·  ê´‘ê³ ë¹„
    'clicks': 'mean',     # ì¼ì¼ í‰ê·  í´ë¦­ìˆ˜
    'roas': 'mean',       # ì¼ì¼ í‰ê·  ROAS
    'ì¹´í…Œê³ ë¦¬': 'first', 
    'ë¸Œëœë“œ': 'first'
}).reset_index().sort_values(['ìƒí’ˆëª…', 'ì£¼ë¬¸ë‚ ì§œ'])
```

#### 10.3 ì‹œê³„ì—´ í”¼ì²˜ ìƒì„±

```python
df_daily['ìˆ˜ëŸ‰_lag_1'] = df_daily.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(1)
df_daily['ìˆ˜ëŸ‰_lag_7'] = df_daily.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(7)
```

#### 10.4 ëª¨ë¸ í•™ìŠµ

```python
features = ['ìƒí’ˆëª…', 'ì¹´í…Œê³ ë¦¬', 'ë¸Œëœë“œ', 'ìˆ˜ëŸ‰_lag_1', 'ìˆ˜ëŸ‰_lag_7', 
            'spend', 'clicks', 'roas']
X = df_model[features]
y = df_model['ìˆ˜ëŸ‰']

model = RandomForestRegressor(n_estimators=200, random_state=42)
model.fit(X_train, y_train)
```

**ì¶”ê°€ëœ ë§ˆì¼€íŒ… í”¼ì²˜**:
- `spend`: ê´‘ê³ ë¹„
- `clicks`: í´ë¦­ ìˆ˜
- `roas`: ê´‘ê³  íˆ¬ì ëŒ€ë¹„ ìˆ˜ìµë¥ 

**ì„±ëŠ¥**: ì •í™•ë„ 61.62%

### Cell 82: íŠ¹ì • ìƒí’ˆ ë¶„ì„ (Pet Treats)

**ëª©ì **: ë‹¨ì¼ ìƒí’ˆì— ëŒ€í•œ ì‹¬í™” ë¶„ì„

```python
target_name = 'Pet Treats'
df_target = df_combined[df_combined['ìƒí’ˆëª…'] == target_name].copy()

# ì¼ë³„ ì§‘ê³„
df_daily_target = df_target.groupby('ì£¼ë¬¸ë‚ ì§œ').agg({
    'ìˆ˜ëŸ‰': 'sum',
    'í‰ì ': 'mean',
    'spend': 'sum',
    'clicks': 'sum'
}).reset_index().sort_values('ì£¼ë¬¸ë‚ ì§œ')
```

**íŠ¹ì§•**:
- íŠ¹ì • ìƒí’ˆë§Œ í•„í„°ë§í•˜ì—¬ ë¶„ì„
- í•´ë‹¹ ìƒí’ˆì˜ ì¼ì¼ ì´ íŒë§¤ëŸ‰ ë° ë§ˆì¼€íŒ… ì§€í‘œ ì§‘ê³„

**ì„±ëŠ¥**: ì •í™•ë„ 67.82% (ì „ì²´ ìƒí’ˆ í‰ê· ë³´ë‹¤ ë†’ìŒ)

### Cell 83: 6ê°œ ìƒí’ˆë³„ ë¶„ì„

**ë¶„ì„ ëŒ€ìƒ ìƒí’ˆ**:
- Toilet Cleaner
- Cough Syrup
- Lotion
- Dish Soap
- Vitamins
- Baby Wipes

**ì²˜ë¦¬ ê³¼ì •**:
```python
for product in target_products:
    # 1. ìƒí’ˆ í•„í„°ë§ ë° ì¼ë³„ ì§‘ê³„
    df_p = df_with_mkt[df_with_mkt['ìƒí’ˆëª…'] == product].copy()
    df_daily = df_p.groupby('ì£¼ë¬¸ë‚ ì§œ').agg({
        'ìˆ˜ëŸ‰': 'sum', 'í‰ì ': 'mean', 'spend': 'sum', 'clicks': 'sum'
    }).reset_index().sort_values('ì£¼ë¬¸ë‚ ì§œ')
    
    # 2. ì‹œê³„ì—´ ë³€ìˆ˜ ìƒì„±
    df_daily['ìˆ˜ëŸ‰_lag_1'] = df_daily['ìˆ˜ëŸ‰'].shift(1)
    df_daily['ìˆ˜ëŸ‰_lag_7'] = df_daily['ìˆ˜ëŸ‰'].shift(7)
    
    # 3. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
    # ...
```

**ê²°ê³¼**:
| ìƒí’ˆëª… | ì •í™•ë„ | í‰ê· ì˜¤ì°¨(MAE) |
|--------|--------|---------------|
| Dish Soap | 67.06% | 0.87ê°œ |
| Lotion | 63.94% | 0.74ê°œ |
| Toilet Cleaner | 58.62% | 1.02ê°œ |
| Vitamins | 58.27% | 1.10ê°œ |
| Cough Syrup | 52.64% | 1.01ê°œ |
| Baby Wipes | 48.89% | 1.04ê°œ |

### Cell 84: ìƒí’ˆë³„ ìƒì„¸ ë¶„ì„ ë° ì‹œê°í™”

**ê°œì„  ì‚¬í•­**:
- `ì£¼ë¬¸_ì¦ê°€ëŸ‰` í”¼ì²˜ ì¶”ê°€ (ìµœê·¼ ì¶”ì„¸ ë°˜ì˜)
- ìµœì†Œ ë°ì´í„° ê°œìˆ˜ í™•ì¸ (30ì¼ ì´ìƒ)
- ìƒì„¸í•œ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±

**ìƒì„±ë˜ëŠ” ë¦¬í¬íŠ¸**:
- ìƒí’ˆëª…
- ë°ì´í„° ì¼ìˆ˜
- í‰ê· ì˜¤ì°¨(MAE)
- ì •í™•ë„

**ì‹œê°í™”**:
- ìƒí’ˆë³„ ì •í™•ë„ ë¹„êµ ë§‰ëŒ€ ê·¸ë˜í”„
- í‰ê·  ì •í™•ë„ ë¼ì¸(60%) í‘œì‹œ

---

## 11ë‹¨ê³„: ì¬ê³  ë°ì´í„° í†µí•©

### Cell 85: ì£¼ë¬¸+ë§ˆì¼€íŒ…+ì¬ê³  í†µí•©

**ëª©ì **: ì¬ê³  ì •ë³´ë¥¼ ì¶”ê°€í•˜ì—¬ ë” ì •í™•í•œ ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•

#### 11.1 ë°ì´í„° ë¡œë“œ ë° ë‚ ì§œ í˜•ì‹ ë³€í™˜

```python
df_final = pd.read_csv('blinkit_final_data.csv')
df_marketing = pd.read_csv(r'data\blinkit_marketing_performance.csv')
df_inv = pd.read_csv(r'data\blinkit_inventory.csv')

# ë‚ ì§œ í˜•ì‹ ë³€í™˜
df_final['ì£¼ë¬¸ë‚ ì§œ'] = pd.to_datetime(df_final['ì£¼ë¬¸ë‚ ì§œ'])
df_marketing['date'] = pd.to_datetime(df_marketing['date'])
df_inv['date'] = pd.to_datetime(df_inv['date'], dayfirst=True)  # DD-MM-YYYY í˜•ì‹
```

**ì¤‘ìš”**: ì¬ê³  ë°ì´í„°ì˜ ë‚ ì§œ í˜•ì‹ì´ `DD-MM-YYYY`ì´ë¯€ë¡œ `dayfirst=True` ì˜µì…˜ ì‚¬ìš©

#### 11.2 ë§ˆì¼€íŒ… ë°ì´í„° ê²°í•©

```python
mkt_mapping = {'Regular': 'All', 'New': 'New Users', 
               'Inactive': 'Inactive', 'Premium': 'Premium'}
df_final['target_audience'] = df_final['íšŒì›íƒ€ì…'].map(mkt_mapping)

df_mkt_agg = df_marketing.groupby(['date', 'target_audience']).agg({
    'spend': 'sum', 'clicks': 'sum', 'roas': 'mean'
}).reset_index()

df_master = pd.merge(df_final, df_mkt_agg, 
                     left_on=['ì£¼ë¬¸ë‚ ì§œ', 'target_audience'], 
                     right_on=['date', 'target_audience'], how='left')
```

#### 11.3 ì¬ê³  ë°ì´í„° ê²°í•©

```python
df_master = pd.merge(df_master, df_inv, 
                     left_on=['ì£¼ë¬¸ë‚ ì§œ', 'ìƒí’ˆ_ID'], 
                     right_on=['date', 'product_id'], how='left').fillna(0)
```

**ë³‘í•© ê¸°ì¤€**:
- `ì£¼ë¬¸ë‚ ì§œ` = `date`
- `ìƒí’ˆ_ID` = `product_id`

**ì¶”ê°€ë˜ëŠ” ì¬ê³  ì •ë³´**:
- `stock_received`: ì…ê³ ìˆ˜ëŸ‰
- `damaged_stock`: íŒŒì†ìˆ˜ëŸ‰

#### 11.4 ì¼ë³„/ìƒí’ˆë³„ ì§‘ê³„

```python
df_daily = df_master.groupby(['ì£¼ë¬¸ë‚ ì§œ', 'ìƒí’ˆëª…']).agg({
    'ìˆ˜ëŸ‰': 'sum',
    'í‰ì ': 'mean',
    'spend': 'mean',
    'clicks': 'mean',
    'stock_received': 'sum',   # ì¬ê³  ì…ê³ ëŸ‰
    'damaged_stock': 'sum',    # ì¬ê³  íŒŒì†ëŸ‰
    'ì¹´í…Œê³ ë¦¬': 'first',
    'ë¸Œëœë“œ': 'first'
}).reset_index().sort_values(['ìƒí’ˆëª…', 'ì£¼ë¬¸ë‚ ì§œ'])
```

#### 11.5 ì‹œê³„ì—´ í”¼ì²˜ ìƒì„±

```python
df_daily['ìˆ˜ëŸ‰_lag_1'] = df_daily.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(1)
df_daily['ìˆ˜ëŸ‰_lag_7'] = df_daily.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(7)
df_daily['ì…ê³ _lag_1'] = df_daily.groupby('ìƒí’ˆëª…')['stock_received'].shift(1)
```

**ìƒˆë¡œ ì¶”ê°€ëœ í”¼ì²˜**:
- `ì…ê³ _lag_1`: ì „ì¼ ì…ê³ ëŸ‰ (ì¬ê³  ë³´ì¶©ì´ íŒë§¤ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„)

#### 11.6 ëª¨ë¸ í•™ìŠµ

```python
features = ['ìƒí’ˆëª…', 'ì¹´í…Œê³ ë¦¬', 'ë¸Œëœë“œ', 'ìˆ˜ëŸ‰_lag_1', 'ìˆ˜ëŸ‰_lag_7', 
            'spend', 'clicks', 'stock_received', 'damaged_stock', 'ì…ê³ _lag_1']
```

**ì¶”ê°€ëœ ì¬ê³  í”¼ì²˜**:
- `stock_received`: ì…ê³ ìˆ˜ëŸ‰
- `damaged_stock`: íŒŒì†ìˆ˜ëŸ‰
- `ì…ê³ _lag_1`: ì „ì¼ ì…ê³ ëŸ‰

**ì„±ëŠ¥**:
- MAE: 0.85ê°œ
- ì •í™•ë„: 62.61%

---

## 12ë‹¨ê³„: ìƒê´€ê´€ê³„ ë¶„ì„

### Cell 86: íŒë§¤-ë§ˆì¼€íŒ…-ì¬ê³  ìƒê´€ê´€ê³„

**ëª©ì **: íŒë§¤, ë§ˆì¼€íŒ…, ì¬ê³  ë³€ìˆ˜ë“¤ ê°„ì˜ ê´€ê³„ íŒŒì•…

```python
# ë°ì´í„° 3ì¢… í†µí•©
df_final = pd.merge(df_sales, df_mkt_agg, 
                    left_on=['ì£¼ë¬¸ë‚ ì§œ', 'target_audience'], 
                    right_on=['date', 'target_audience'], how='left')
df_final = pd.merge(df_final, df_inventory, 
                    left_on=['ì£¼ë¬¸ë‚ ì§œ', 'ìƒí’ˆ_ID'], 
                    right_on=['date', 'product_id'], how='left')

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
df_final[['spend', 'clicks', 'stock_received', 'damaged_stock']] = \
    df_final[['spend', 'clicks', 'stock_received', 'damaged_stock']].fillna(0)

# ìƒê´€ê´€ê³„ ë¶„ì„
corr_cols = ['ìˆ˜ëŸ‰', 'ê¸ˆì•¡', 'í‰ì ', 'spend', 'clicks', 
             'stock_received', 'damaged_stock']
corr_matrix = df_final[corr_cols].corr()

# íˆíŠ¸ë§µ ì‹œê°í™”
sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0)
```

**ë¶„ì„ ë³€ìˆ˜**:
- **íŒë§¤**: ìˆ˜ëŸ‰, ê¸ˆì•¡, í‰ì 
- **ë§ˆì¼€íŒ…**: spend, clicks
- **ì¬ê³ **: stock_received, damaged_stock

**íˆíŠ¸ë§µ í•´ì„**:
- ê° ë³€ìˆ˜ ê°„ì˜ ìƒê´€ê³„ìˆ˜ í™•ì¸
- ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„: í•¨ê»˜ ì¦ê°€/ê°ì†Œ
- ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„: ë°˜ëŒ€ë¡œ ì›€ì§ì„

### Cell 87: ì¹´í…Œê³ ë¦¬ ê°„ ë§¤ì¶œ ìƒê´€ê´€ê³„

**ëª©ì **: ì„œë¡œ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ ê°„ì˜ ë§¤ì¶œ ìƒê´€ê´€ê³„ íŒŒì•…

```python
# ì¼ë³„/ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ì§‘ê³„
df_cat_sales = df_combined.groupby(['ì£¼ë¬¸ë‚ ì§œ', 'ì¹´í…Œê³ ë¦¬'])['ê¸ˆì•¡'].sum().reset_index()

# í”¼ë²— í…Œì´ë¸” ìƒì„±
cat_pivot = df_cat_sales.pivot(index='ì£¼ë¬¸ë‚ ì§œ', columns='ì¹´í…Œê³ ë¦¬', values='ê¸ˆì•¡').fillna(0)

# ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ê³„ì‚°
cat_corr = cat_pivot.corr()
```

**í”¼ë²— í…Œì´ë¸” êµ¬ì¡°**:
- **í–‰**: ì£¼ë¬¸ë‚ ì§œ
- **ì—´**: ì¹´í…Œê³ ë¦¬
- **ê°’**: ë§¤ì¶œ(ê¸ˆì•¡)

**ìƒê´€ê´€ê³„ í•´ì„**:
- ë†’ì€ ìƒê´€ê´€ê³„: ë‘ ì¹´í…Œê³ ë¦¬ê°€ í•¨ê»˜ íŒ”ë¦¬ëŠ” ê²½í–¥
- ë‚®ì€ ìƒê´€ê´€ê³„: ë…ë¦½ì ìœ¼ë¡œ íŒ”ë¦¬ëŠ” ê²½í–¥

**ê²°ê³¼ (TOP 5)**:
1. Snacks & Munchies â†” Grocery & Staples: 0.093
2. Snacks & Munchies â†” Pharmacy: 0.080
3. Dairy & Breakfast â†” Instant & Frozen Food: 0.066
4. Baby Care â†” Dairy & Breakfast: 0.054
5. Snacks & Munchies â†” Pet Care: 0.052

---

## 13ë‹¨ê³„: ì£¼ë³„ ë°ì´í„° ì§‘ê³„

### Cell 88: ì¼ë³„ vs ì£¼ë³„ ëª¨ë¸ ë¹„êµ

**ëª©ì **: ë°ì´í„° ì§‘ê³„ ë‹¨ìœ„ì— ë”°ë¥¸ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ

```python
def train_and_evaluate(data, target_col='ìˆ˜ëŸ‰'):
    # í”¼ì²˜ ìƒì„±
    data['lag_1'] = data[target_col].shift(1)
    data['lag_2'] = data[target_col].shift(2)
    # ... ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
    return accuracy

# ì¼ë³„ ë°ì´í„°
df_daily = df_target.groupby('ì£¼ë¬¸ë‚ ì§œ').agg({
    'ìˆ˜ëŸ‰': 'sum', 'spend': 'sum', 'clicks': 'sum'
}).reset_index().sort_values('ì£¼ë¬¸ë‚ ì§œ')
daily_acc = train_and_evaluate(df_daily)

# ì£¼ë³„ ë°ì´í„°
df_weekly = df_target.set_index('ì£¼ë¬¸ë‚ ì§œ').resample('W').agg({
    'ìˆ˜ëŸ‰': 'sum', 'spend': 'sum', 'clicks': 'sum'
}).reset_index()
weekly_acc = train_and_evaluate(df_weekly)
```

**ë¹„êµ ê²°ê³¼** (Pet Treats ìƒí’ˆ):
- ì¼ë³„ ì •í™•ë„: 69.04%
- ì£¼ë³„ ì •í™•ë„: 71.32%
- **ì£¼ë³„ì´ 2.28%p ë” ë†’ìŒ**

**ì´ìœ **:
- ì£¼ë³„ ì§‘ê³„ë¡œ ë…¸ì´ì¦ˆ ê°ì†Œ
- ì£¼ê°„ íŒ¨í„´ì´ ë” ì•ˆì •ì 
- ì¼ë³„ ë³€ë™ì„±ì´ í‰ê· í™”ë¨

### Cell 89: ì£¼ë³„ ë°ì´í„° ìƒì„± ë° ë¶„ì„

#### 13.1 ì£¼ë³„ ì§‘ê³„

```python
df_weekly = df_master.set_index('ì£¼ë¬¸ë‚ ì§œ').resample('W').agg({
    'ìˆ˜ëŸ‰': 'sum',              # ì£¼ê°„ ì´ íŒë§¤ëŸ‰
    'ê¸ˆì•¡': 'sum',              # ì£¼ê°„ ì´ ë§¤ì¶œ
    'í‰ì ': 'mean',             # ì£¼ê°„ í‰ê·  í‰ì 
    'spend': 'sum',             # ì£¼ê°„ ì´ ê´‘ê³ ë¹„
    'clicks': 'sum',            # ì£¼ê°„ ì´ í´ë¦­ìˆ˜
    'stock_received': 'sum',    # ì£¼ê°„ ì´ ì…ê³ ëŸ‰
    'damaged_stock': 'sum'      # ì£¼ê°„ ì´ íŒŒì†ëŸ‰
}).reset_index()
```

**resample('W')ì˜ ë™ì‘**:
- ì£¼ ë‹¨ìœ„ë¡œ ë°ì´í„° ì¬ìƒ˜í”Œë§
- ì¼ìš”ì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì£¼ ë‹¨ìœ„ ê·¸ë£¹í™”
- ê° ì£¼ì˜ ë°ì´í„°ë¥¼ í•©ì‚°/í‰ê· 

**ì§‘ê³„ í•¨ìˆ˜**:
- `sum`: ìˆ˜ëŸ‰, ê¸ˆì•¡, spend, clicks, stock_received, damaged_stock
- `mean`: í‰ì 

#### 13.2 ì£¼ë³„ ìƒê´€ê´€ê³„ ë¶„ì„

```python
corr_cols = ['ìˆ˜ëŸ‰', 'ê¸ˆì•¡', 'í‰ì ', 'spend', 'clicks', 
             'stock_received', 'damaged_stock']
weekly_corr = df_weekly[corr_cols].corr()

sns.heatmap(weekly_corr, annot=True, cmap='coolwarm', center=0, fmt='.2f')
```

**ê²°ê³¼**: ì£¼ ë‹¨ìœ„ë¡œ ì§‘ê³„ëœ ë°ì´í„°ì˜ ìƒê´€ê´€ê³„ í–‰ë ¬

### Cell 90: ì£¼ë³„ ë°ì´í„° ì €ì¥

```python
df_weekly.to_csv(r'data\merged_data\blinkit_weekly_data.csv', 
                 index=False, encoding='utf-8-sig')
```

**ì €ì¥ë˜ëŠ” ë°ì´í„°**:
- **íŒŒì¼ëª…**: `blinkit_weekly_data.csv`
- **í–‰ ìˆ˜**: 87í–‰ (ì•½ 87ì£¼)
- **ì»¬ëŸ¼ ìˆ˜**: 8ê°œ
  - ì£¼ë¬¸ë‚ ì§œ, ìˆ˜ëŸ‰, ê¸ˆì•¡, í‰ì , spend, clicks, stock_received, damaged_stock

---

## 14ë‹¨ê³„: ì£¼ë³„+ì œí’ˆë³„ ë¶„ì„

### Cell 93: ì£¼ë³„+ì œí’ˆë³„ ì§‘ê³„

**ëª©ì **: ê° ìƒí’ˆë³„ë¡œ ì£¼ê°„ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ ìƒí’ˆë³„ ì£¼ê°„ íŒ¨í„´ ë¶„ì„

```python
df_weekly_product = df_master.groupby([
    pd.Grouper(key='ì£¼ë¬¸ë‚ ì§œ', freq='W'),  # ì£¼ ë‹¨ìœ„ ê·¸ë£¹í™”
    'ìƒí’ˆëª…'                                # ìƒí’ˆë³„ ê·¸ë£¹í™”
]).agg({
    'ìˆ˜ëŸ‰': 'sum',
    'ê¸ˆì•¡': 'sum',
    'í‰ì ': 'mean',
    'spend': 'sum',
    'clicks': 'sum',
    'stock_received': 'sum',
    'damaged_stock': 'sum'
}).reset_index()
```

**pd.Grouperì˜ ì—­í• **:
- ë‚ ì§œë¥¼ ì£¼ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”
- `freq='W'`: ì£¼ ë‹¨ìœ„ (ì¼ìš”ì¼ ê¸°ì¤€)

**ê²°ê³¼ êµ¬ì¡°**:
- ê° ì£¼, ê° ìƒí’ˆë³„ë¡œ í•˜ë‚˜ì˜ í–‰
- ì˜ˆ: 2023-03-19 ì£¼ì˜ Pet Treats ë°ì´í„°, 2023-03-19 ì£¼ì˜ Toilet Cleaner ë°ì´í„° ë“±

**í™œìš©**:
- ìƒí’ˆë³„ ì£¼ê°„ íŒë§¤ íŒ¨í„´ ë¶„ì„
- ìƒí’ˆë³„ ë§ˆì¼€íŒ… íš¨ê³¼ ë¶„ì„
- ìƒí’ˆë³„ ì¬ê³  ê´€ë¦¬ ìµœì í™”

### Cell 94: ë°ì´í„° ì €ì¥

```python
df_weekly_product.to_csv('blinkit_weekly_product_analysis.csv', 
                         index=False, encoding='utf-8-sig')
```

---

## 15ë‹¨ê³„: Top 10 ìƒí’ˆ ë¶„ì„

### Cell 96: Top 10 ìƒí’ˆë³„ ìƒê´€ê´€ê³„ ë¹„êµ

**ë¶„ì„ ëŒ€ìƒ ìƒí’ˆ**:
1. Pet Treats
2. Toilet Cleaner
3. Lotion
4. Vitamins
5. Dish Soap
6. Baby Wipes
7. Cough Syrup
8. Cat Food
9. Pulses
10. Orange Juice

**ì²˜ë¦¬ ê³¼ì •**:
```python
# Top 10ë§Œ ì¶”ì¶œ
df_top_10 = df_weekly_product[df_weekly_product['ìƒí’ˆëª…'].isin(top_10_products)]

# ê° ìƒí’ˆë³„ë¡œ ìˆ˜ëŸ‰ê³¼ì˜ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
for product in top_10_products:
    product_df = df_top_10[df_top_10['ìƒí’ˆëª…'] == product]
    product_corr = product_df[['ìˆ˜ëŸ‰', 'ê¸ˆì•¡', 'í‰ì ', 'spend', 'clicks', 
                                'stock_received', 'damaged_stock']].corr()['ìˆ˜ëŸ‰']
    corr_summary.append(product_corr)

# ê²°ê³¼ í•©ì¹˜ê¸°
df_corr_comparison = pd.concat(corr_summary, axis=1).T.drop(columns=['ìˆ˜ëŸ‰'])
```

**ìƒì„±ë˜ëŠ” ë°ì´í„°**:
- ê° ìƒí’ˆë³„ë¡œ ìˆ˜ëŸ‰ê³¼ ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì˜ ìƒê´€ê³„ìˆ˜
- ì˜ˆ: Pet Treatsì˜ ìˆ˜ëŸ‰ê³¼ spendì˜ ìƒê´€ê³„ìˆ˜, ìˆ˜ëŸ‰ê³¼ clicksì˜ ìƒê´€ê³„ìˆ˜ ë“±

**ì‹œê°í™”**:
- ìƒí’ˆë³„ ë§ˆì¼€íŒ…/ì¬ê³  ë¯¼ê°ë„ íˆíŠ¸ë§µ
- ì–´ë–¤ ìƒí’ˆì´ ì–´ë–¤ ë³€ìˆ˜ì— ë¯¼ê°í•œì§€ í•œëˆˆì— íŒŒì•…

### Cell 97-98: ê°€ì¤‘ì¹˜ ê¸°ë°˜ ëª¨ë¸

#### 15.1 ë³€ìˆ˜ ì •ê·œí™”

```python
scaler = MinMaxScaler()
features_to_scale = ['ê¸ˆì•¡', 'í‰ì ', 'spend', 'clicks', 
                     'stock_received', 'damaged_stock']
df_model_data[features_to_scale] = scaler.fit_transform(df_model_data[features_to_scale])
```

**ì •ê·œí™” ì´ìœ **:
- ê¸ˆì•¡(ìˆ˜ë§Œ ë‹¨ìœ„)ê³¼ í‰ì (1~5 ë‹¨ìœ„)ì˜ ìŠ¤ì¼€ì¼ ì°¨ì´
- ëª¨ë“  ë³€ìˆ˜ë¥¼ 0~1 ì‚¬ì´ë¡œ ë³€í™˜í•˜ì—¬ ê³µì •í•œ ê°€ì¤‘ì¹˜ ê³„ì‚°

**MinMaxScalerì˜ ë™ì‘**:
- ìµœì†Œê°’ì„ 0, ìµœëŒ€ê°’ì„ 1ë¡œ ë³€í™˜
- ì¤‘ê°„ê°’ì€ ë¹„ë¡€ì ìœ¼ë¡œ ë³€í™˜

#### 15.2 ê°€ì¤‘í•© í”¼ì²˜ ìƒì„±

```python
def apply_weights(row):
    product = row['ìƒí’ˆëª…']
    if product in df_corr_comparison.index:
        weights = df_corr_comparison.loc[product]
        weighted_score = (
            row['í‰ì '] * weights['í‰ì '] +
            row['spend'] * weights['spend'] +
            row['clicks'] * weights['clicks'] +
            row['stock_received'] * weights['stock_received'] +
            row['damaged_stock'] * weights['damaged_stock']
        )
        return weighted_score
    return 0

df_model_data['weighted_score'] = df_model_data.apply(apply_weights, axis=1)
```

**ê°€ì¤‘í•©ì˜ ì˜ë¯¸**:
- ê° ë³€ìˆ˜ì— ìƒê´€ê³„ìˆ˜ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ê³±í•˜ì—¬ í•©ì‚°
- ìƒê´€ê³„ìˆ˜ê°€ ë†’ì€ ë³€ìˆ˜ì˜ ì˜í–¥ë ¥ì´ ë” í¬ê²Œ ë°˜ì˜
- ì˜ˆì¸¡ ì§€ìˆ˜ ì—­í• 

**ì˜ˆì‹œ**:
- Pet Treatsì˜ spend ìƒê´€ê³„ìˆ˜ê°€ 0.5ë¼ë©´
- spend ê°’ì— 0.5ë¥¼ ê³±í•˜ì—¬ weighted_scoreì— ë”í•¨

#### 15.3 ëª¨ë¸ í•™ìŠµ

```python
def train_and_predict(product_name):
    product_df = df_model_data[df_model_data['ìƒí’ˆëª…'] == product_name]
    
    X = product_df[['weighted_score', 'lag_1', 'spend', 'í‰ì ', 'stock_received']]
    y = product_df['ìˆ˜ëŸ‰']
    
    # 8:2 ë¶„í• 
    split = int(len(X) * 0.8)
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]
    
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    # ì„±ëŠ¥ ê³„ì‚°
    ...
```

**í”¼ì²˜ êµ¬ì„±**:
- `weighted_score`: ê°€ì¤‘í•© ì ìˆ˜
- `lag_1`: ì „ì£¼ íŒë§¤ëŸ‰
- `spend`: ê´‘ê³ ë¹„
- `í‰ì `: í‰ì 
- `stock_received`: ì…ê³ ëŸ‰

**ì„±ëŠ¥ ê²°ê³¼** (Top 10):
| ìƒí’ˆëª… | ì •í™•ë„ | MAE | RÂ² |
|--------|--------|-----|-----|
| Pet Treats | 75.38% | 1.89 | 0.57 |
| Pulses | 71.32% | 1.01 | 0.48 |
| Vitamins | 69.44% | 1.78 | 0.50 |
| Lotion | 69.25% | 1.17 | 0.69 |
| Cough Syrup | 66.97% | 1.52 | 0.52 |
| Cat Food | 65.49% | 1.68 | 0.53 |
| Dish Soap | 61.61% | 2.46 | 0.11 |
| Orange Juice | 61.05% | 1.22 | 0.29 |
| Toilet Cleaner | 60.85% | 1.66 | 0.24 |
| Baby Wipes | 59.31% | 1.60 | -0.18 |

---

## 16ë‹¨ê³„: ê³ ë„í™” ëª¨ë¸

### Cell 99: ê°€ì¤‘ì¹˜ ê³ ë„í™” ë° ì‹œê³„ì—´ í”¼ì²˜ í™•ì¥

#### 16.1 ê³ ë„í™”ëœ ê°€ì¤‘í•©

**ê°œì„  ì‚¬í•­**: ìƒê´€ê³„ìˆ˜ì˜ ì œê³±ì„ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©

```python
def apply_optimized_weights(row):
    product = row['ìƒí’ˆëª…']
    if product in df_corr_comparison.index:
        weights = df_corr_comparison.loc[product]
        # ìƒê´€ê³„ìˆ˜ì˜ ì œê³± ì‚¬ìš© (ë¹„ì„ í˜• ê°€ì¤‘)
        weighted_score = (
            row['í‰ì '] * (weights['í‰ì ']**2) +
            row['spend'] * (weights['spend']**2) +
            row['clicks'] * (weights['clicks']**2) +
            row['stock_received'] * (weights['stock_received']**2)
        )
        return weighted_score
    return 0
```

**ì œê³±ì„ ì‚¬ìš©í•˜ëŠ” ì´ìœ **:
- ìƒê´€ê³„ìˆ˜ê°€ ë†’ì€ ë³€ìˆ˜ì˜ ì˜í–¥ë ¥ì„ ë¹„ì„ í˜•ì ìœ¼ë¡œ ì¦í­
- ì˜ˆ: ìƒê´€ê³„ìˆ˜ 0.5 â†’ ê°€ì¤‘ì¹˜ 0.25, ìƒê´€ê³„ìˆ˜ 0.8 â†’ ê°€ì¤‘ì¹˜ 0.64
- ì¤‘ìš”í•œ ë³€ìˆ˜ì™€ ëœ ì¤‘ìš”í•œ ë³€ìˆ˜ì˜ ì°¨ì´ë¥¼ ë” ëª…í™•íˆ í•¨

#### 16.2 ìƒê¸‰ ì‹œê³„ì—´ í”¼ì²˜ ìƒì„±

```python
# ê³¼ê±° 1~2ì£¼ ë°ì´í„°
df_model_data['lag_1'] = df_model_data.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(1)
df_model_data['lag_2'] = df_model_data.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].shift(2)

# 3ì£¼ ì´ë™ í‰ê· 
df_model_data['rolling_mean_3'] = df_model_data.groupby('ìƒí’ˆëª…')['ìˆ˜ëŸ‰'].transform(
    lambda x: x.rolling(window=3).mean()
)

# ëª¨ë©˜í…€ (íŒë§¤ ê°€ì†ë„)
df_model_data['momentum'] = df_model_data['lag_1'] - df_model_data['lag_2']
```

**ìƒˆë¡œ ì¶”ê°€ëœ í”¼ì²˜**:
- `lag_2`: 2ì£¼ ì „ íŒë§¤ëŸ‰
- `rolling_mean_3`: ìµœê·¼ 3ì£¼ ì´ë™í‰ê·  (ë‹¨ê¸° ì¶”ì„¸)
- `momentum`: íŒë§¤ ê°€ì†ë„
  - ì–‘ìˆ˜: íŒë§¤ëŸ‰ ì¦ê°€ ì¶”ì„¸
  - ìŒìˆ˜: íŒë§¤ëŸ‰ ê°ì†Œ ì¶”ì„¸

#### 16.3 ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¡°ì •

```python
model = RandomForestR