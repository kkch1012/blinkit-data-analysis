"""
MongoDB ì €ì¥ ì˜ˆì‹œ: ì»¬ë ‰ì…˜ êµ¬ì¡°ì— ë§ê²Œ ë°ì´í„° ì €ì¥í•˜ëŠ” ë°©ë²•
"""

from pymongo import MongoClient
from datetime import datetime
import pandas as pd


class MongoDBDataSaver:
    """MongoDBì— ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, connection_string="mongodb://localhost:27017/", db_name="blinkit_analytics"):
        self.client = MongoClient(connection_string)
        self.db = self.client[db_name]
        
        # ì»¬ë ‰ì…˜ ì´ˆê¸°í™” (ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘ )
        self.files = self.db['files']
        self.csv_contents = self.db['csv_contents']
        self.user_suggestions = self.db['user_suggestions']
        self.analysis_results = self.db['analysis_results']
        self.feature_weights = self.db['feature_weights']
    
    def save_csv_file(self, user_id: str, csv_path: str, file_name: str):
        """
        CSV íŒŒì¼ì„ MongoDBì— ì €ì¥
        - ì»¬ë ‰ì…˜ êµ¬ì¡°ì— ë§ê²Œ ì €ì¥
        - CSVë§ˆë‹¤ ì»¬ëŸ¼ëª…ì´ ë‹¬ë¼ë„ OK (data í•„ë“œì— JSONìœ¼ë¡œ ì €ì¥)
        """
        # 1. CSV ì½ê¸°
        df = pd.read_csv(csv_path)
        
        # 2. file_id ìƒì„±
        file_id = f"file_{datetime.now().strftime('%Y%m%d%H%M%S')}_{user_id}"
        
        # 3. files ì»¬ë ‰ì…˜ì— ë©”íƒ€ë°ì´í„° ì €ì¥ (êµ¬ì¡° ê³ ì •)
        file_doc = {
            "file_id": file_id,                    # âœ… ê³ ì • í•„ë“œ
            "user_id": user_id,                     # âœ… ê³ ì • í•„ë“œ
            "file_name": file_name,                 # âœ… ê³ ì • í•„ë“œ
            "file_size": len(df),                   # âœ… ê³ ì • í•„ë“œ
            "columns": df.columns.tolist(),         # âœ… ê³ ì • í•„ë“œ (ë°°ì—´)
            "column_types": {                       # âœ… ê³ ì • í•„ë“œ (ë”•ì…”ë„ˆë¦¬)
                col: str(df[col].dtype) for col in df.columns
            },
            "row_count": len(df),                   # âœ… ê³ ì • í•„ë“œ
            "uploaded_at": datetime.now(),          # âœ… ê³ ì • í•„ë“œ
            "status": "uploaded"                    # âœ… ê³ ì • í•„ë“œ
        }
        
        self.files.insert_one(file_doc)
        print(f"âœ… files ì»¬ë ‰ì…˜ì— ì €ì¥ ì™„ë£Œ: {file_id}")
        
        # 4. csv_contents ì»¬ë ‰ì…˜ì— ì‹¤ì œ ë°ì´í„° ì €ì¥ (êµ¬ì¡° ê³ ì •, ë‚´ìš© ìœ ì—°)
        csv_docs = []
        
        for idx, row in df.iterrows():
            # âœ… ì»¬ë ‰ì…˜ êµ¬ì¡°ëŠ” ê³ ì • (file_id, user_id, row_index, data, created_at)
            # âœ… í•˜ì§€ë§Œ data í•„ë“œ ì•ˆì˜ ë‚´ìš©ì€ CSVë§ˆë‹¤ ë‹¬ë¼ë„ OK!
            doc = {
                "file_id": file_id,                 # âœ… ê³ ì • í•„ë“œ
                "user_id": user_id,                 # âœ… ê³ ì • í•„ë“œ
                "row_index": int(idx),              # âœ… ê³ ì • í•„ë“œ
                "data": row.to_dict(),              # âœ… ìœ ì—°í•œ í•„ë“œ (CSVë§ˆë‹¤ ë‹¤ë¦„)
                "created_at": datetime.now()        # âœ… ê³ ì • í•„ë“œ
            }
            csv_docs.append(doc)
            
            # ë°°ì¹˜ ì‚½ì… (1000ê°œì”©)
            if len(csv_docs) >= 1000:
                self.csv_contents.insert_many(csv_docs)
                csv_docs = []
        
        # ë‚¨ì€ ë°ì´í„° ì‚½ì…
        if csv_docs:
            self.csv_contents.insert_many(csv_docs)
        
        print(f"âœ… csv_contents ì»¬ë ‰ì…˜ì— {len(df)}ê°œ í–‰ ì €ì¥ ì™„ë£Œ")
        
        return file_id
    
    def save_suggestions(self, file_id: str, user_id: str, suggestions: list):
        """
        ì œì•ˆ ì €ì¥ (êµ¬ì¡° ê³ ì •)
        """
        suggestion_doc = {
            "file_id": file_id,                     # âœ… ê³ ì • í•„ë“œ
            "user_id": user_id,                     # âœ… ê³ ì • í•„ë“œ
            "suggestions": suggestions,             # âœ… ê³ ì • í•„ë“œ (ë°°ì—´)
            "created_at": datetime.now()            # âœ… ê³ ì • í•„ë“œ
        }
        
        self.user_suggestions.insert_one(suggestion_doc)
        print(f"âœ… user_suggestions ì»¬ë ‰ì…˜ì— ì €ì¥ ì™„ë£Œ")
    
    def save_analysis_result(self, file_id: str, user_id: str, metrics: dict):
        """
        ë¶„ì„ ê²°ê³¼ ì €ì¥ (êµ¬ì¡° ê³ ì •)
        """
        analysis_doc = {
            "analysis_id": f"analysis_{datetime.now().strftime('%Y%m%d%H%M%S')}",
            "file_id": file_id,                     # âœ… ê³ ì • í•„ë“œ
            "user_id": user_id,                     # âœ… ê³ ì • í•„ë“œ
            "analysis_type": "auto_feature_engineering",  # âœ… ê³ ì • í•„ë“œ
            "result": {                             # âœ… ê³ ì • í•„ë“œ (ë”•ì…”ë„ˆë¦¬)
                "metrics": metrics,
                "created_at": datetime.now().isoformat()
            },
            "created_at": datetime.now()            # âœ… ê³ ì • í•„ë“œ
        }
        
        self.analysis_results.insert_one(analysis_doc)
        print(f"âœ… analysis_results ì»¬ë ‰ì…˜ì— ì €ì¥ ì™„ë£Œ")
    
    def save_feature_weights(self, file_id: str, user_id: str, weights: dict, metrics: dict):
        """
        í”¼ì²˜ ê°€ì¤‘ì¹˜ ì €ì¥ (êµ¬ì¡° ê³ ì •)
        """
        weight_doc = {
            "weight_id": f"weight_{datetime.now().strftime('%Y%m%d%H%M%S')}",
            "file_id": file_id,                     # âœ… ê³ ì • í•„ë“œ
            "user_id": user_id,                     # âœ… ê³ ì • í•„ë“œ
            "weights": weights,                     # âœ… ê³ ì • í•„ë“œ (ë”•ì…”ë„ˆë¦¬)
            "model_metrics": metrics,               # âœ… ê³ ì • í•„ë“œ (ë”•ì…”ë„ˆë¦¬)
            "created_at": datetime.now()            # âœ… ê³ ì • í•„ë“œ
        }
        
        self.feature_weights.insert_one(weight_doc)
        print(f"âœ… feature_weights ì»¬ë ‰ì…˜ì— ì €ì¥ ì™„ë£Œ")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    saver = MongoDBDataSaver()
    
    # ì˜ˆì‹œ 1: í•œê¸€ ì»¬ëŸ¼ëª… CSV
    print("="*60)
    print("ì˜ˆì‹œ 1: í•œê¸€ ì»¬ëŸ¼ëª… CSV ì €ì¥")
    print("="*60)
    file_id1 = saver.save_csv_file(
        user_id="user123",
        csv_path="data/blinkit_with_weather.csv",
        file_name="blinkit_with_weather.csv"
    )
    
    # ì œì•ˆ ì €ì¥
    saver.save_suggestions(
        file_id=file_id1,
        user_id="user123",
        suggestions=[
            "ğŸ’° 'ê¸ˆì•¡' ì»¬ëŸ¼ì´ ìˆë„¤ìš”! í•©ê³„ë¥¼ êµ¬í•´ë“œë¦´ê¹Œìš”?",
            "ğŸ“¦ 'ìˆ˜ëŸ‰' ì»¬ëŸ¼ì´ ìˆë„¤ìš”! ì´ íŒë§¤ëŸ‰ì„ ê³„ì‚°í•´ë“œë¦´ê¹Œìš”?"
        ]
    )
    
    # ë¶„ì„ ê²°ê³¼ ì €ì¥
    saver.save_analysis_result(
        file_id=file_id1,
        user_id="user123",
        metrics={
            "mae": 1.23,
            "r2": 0.65,
            "accuracy": 72.5
        }
    )
    
    # ê°€ì¤‘ì¹˜ ì €ì¥
    saver.save_feature_weights(
        file_id=file_id1,
        user_id="user123",
        weights={
            "ìˆ˜ëŸ‰_lag_1": 0.25,
            "temp_max": 0.15,
            "spend": 0.20
        },
        metrics={
            "mae": 1.23,
            "r2": 0.65,
            "accuracy": 72.5
        }
    )
    
    print("\n" + "="*60)
    print("âœ… ëª¨ë“  ì €ì¥ ì™„ë£Œ!")
    print("="*60)
    
    # ì¡°íšŒ ì˜ˆì‹œ
    print("\nğŸ“Š ì €ì¥ëœ ë°ì´í„° ì¡°íšŒ:")
    
    # files ì»¬ë ‰ì…˜ ì¡°íšŒ
    file_info = saver.files.find_one({"file_id": file_id1})
    print(f"\níŒŒì¼ ì •ë³´:")
    print(f"  - íŒŒì¼ëª…: {file_info['file_name']}")
    print(f"  - ì»¬ëŸ¼: {file_info['columns']}")
    print(f"  - í–‰ ìˆ˜: {file_info['row_count']}")
    
    # csv_contents ì»¬ë ‰ì…˜ ì¡°íšŒ (ì²« 3ê°œ í–‰)
    print(f"\nì‹¤ì œ ë°ì´í„° (ì²« 3ê°œ í–‰):")
    for doc in saver.csv_contents.find({"file_id": file_id1}).limit(3):
        print(f"  í–‰ {doc['row_index']}: {doc['data']}")


"""
í•µì‹¬ ì •ë¦¬:

1. ì»¬ë ‰ì…˜ êµ¬ì¡°ëŠ” ê³ ì • (ì½”ë“œì—ì„œ ì •ì˜)
   - files: file_id, user_id, file_name, columns, ...
   - csv_contents: file_id, user_id, row_index, data, ...

2. í•˜ì§€ë§Œ data í•„ë“œ ì•ˆì˜ ë‚´ìš©ì€ ìœ ì—° (CSVë§ˆë‹¤ ë‹¤ë¦„)
   - CSV 1: {"ì£¼ë¬¸ë‚ ì§œ": "...", "ìƒí’ˆëª…": "..."}
   - CSV 2: {"date": "...", "product": "..."}
   - ëª¨ë‘ ê°™ì€ êµ¬ì¡°ë¡œ ì €ì¥ ê°€ëŠ¥!

3. ì½”ë“œì—ì„œ ì €ì¥í•  ë•Œ:
   - âœ… ì»¬ë ‰ì…˜ì˜ ê³ ì • í•„ë“œëŠ” í•­ìƒ í¬í•¨
   - âœ… data í•„ë“œì—ëŠ” CSVì˜ ëª¨ë“  ì»¬ëŸ¼ì„ JSONìœ¼ë¡œ ì €ì¥
   - âœ… CSVë§ˆë‹¤ ì»¬ëŸ¼ëª…ì´ ë‹¬ë¼ë„ ë¬¸ì œì—†ìŒ
"""

